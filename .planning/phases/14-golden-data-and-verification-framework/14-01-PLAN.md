---
phase: 14-golden-data-and-verification-framework
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - scripts/generate_golden_data.py
  - tests/golden/.gitkeep
autonomous: false
requirements:
  - VER-01

must_haves:
  truths:
    - "Running the generation script on a fixed clip with a fixed seed produces deterministic stage outputs saved as .pt files"
    - "Golden data files are committed in a standalone commit in tests/golden/"
    - "Environment metadata (GPU model, CUDA version, PyTorch version, seed value) is recorded alongside golden data"
    - "Re-running the script on the same clip produces equivalent outputs within GPU tolerance"
  artifacts:
    - path: "scripts/generate_golden_data.py"
      provides: "Standalone golden data generation script"
      min_lines: 80
    - path: "tests/golden/golden_detection.pt"
      provides: "Frozen detection stage outputs"
    - path: "tests/golden/golden_segmentation.pt"
      provides: "Frozen segmentation stage outputs"
    - path: "tests/golden/golden_tracking.pt"
      provides: "Frozen tracking stage outputs"
    - path: "tests/golden/golden_midline_extraction.pt"
      provides: "Frozen midline extraction stage outputs"
    - path: "tests/golden/golden_triangulation.pt"
      provides: "Frozen triangulation stage outputs"
    - path: "tests/golden/metadata.pt"
      provides: "Environment metadata and seed info"
  key_links:
    - from: "scripts/generate_golden_data.py"
      to: "src/aquapose/pipeline/orchestrator.py"
      via: "Calls v1.0 pipeline stages to generate reference outputs"
      pattern: "run_detection|run_segmentation|run_tracking|run_midline_extraction|run_triangulation"
    - from: "scripts/generate_golden_data.py"
      to: "tests/golden/"
      via: "torch.save writes .pt fixture files"
      pattern: "torch\\.save"
---

<objective>
Create the golden data generation script and produce frozen reference outputs from the v1.0 pipeline, committed as a standalone snapshot in `tests/golden/`.

Purpose: Golden data is the regression baseline for all stage migrations in Phase 15-16. Without committed golden data, there is no way to verify that ported stages produce numerically equivalent results.
Output: `scripts/generate_golden_data.py` script + committed `.pt` fixture files in `tests/golden/`.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/14-golden-data-and-verification-framework/14-CONTEXT.md
@src/aquapose/pipeline/orchestrator.py (v1.0 pipeline — reference for stage calling pattern)
@src/aquapose/pipeline/stages.py (v1.0 stage functions — outputs to freeze)

<interfaces>
<!-- Key interfaces the executor needs from the v1.0 pipeline -->

From src/aquapose/pipeline/stages.py:
```python
def run_detection(video_set, stop_frame=None, detector_kind="mog2", **detector_kwargs) -> list[dict[str, list[Detection]]]
def run_segmentation(detections_per_frame, video_set, segmentor, stop_frame=None) -> list[dict[str, list[tuple[np.ndarray, CropRegion]]]]
def run_tracking(detections_per_frame, models, tracker) -> list[list[FishTrack]]
def run_midline_extraction(tracks_per_frame, masks_per_frame, detections_per_frame, extractor) -> list[MidlineSet]
def run_triangulation(midline_sets, models) -> list[dict[int, Midline3D]]
```

From src/aquapose/pipeline/orchestrator.py:
```python
def reconstruct(video_dir, calibration_path, output_dir, *, stop_frame=None, detector_kind="yolo", unet_weights=None, max_fish=9, **detector_kwargs) -> ReconstructResult
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create golden data generation script</name>
  <files>
    scripts/generate_golden_data.py
    tests/golden/.gitkeep
  </files>
  <action>
Create `scripts/generate_golden_data.py` — a standalone script that runs the v1.0 pipeline stage-by-stage on a fixed clip and saves each stage's output as a `.pt` file.

**Script requirements:**

1. **CLI arguments** (via argparse):
   - `--video-dir` (required): Path to directory containing per-camera video files
   - `--calibration` (required): Path to AquaCal calibration JSON
   - `--output-dir` (default: `tests/golden/`): Where to save .pt files
   - `--stop-frame` (default: 30): Number of frames to process
   - `--detector-kind` (default: `"yolo"`): Detector type
   - `--yolo-weights`: Path to YOLO weights (required if detector_kind=yolo)
   - `--unet-weights`: Path to U-Net weights
   - `--seed` (default: 42): Global seed for reproducibility
   - `--max-fish` (default: 9): Max fish for tracker

2. **Determinism setup** — at the very start of `main()`, before any other imports:
   ```python
   import random, numpy as np, torch
   random.seed(seed)
   np.random.seed(seed)
   torch.manual_seed(seed)
   if torch.cuda.is_available():
       torch.cuda.manual_seed_all(seed)
       torch.backends.cudnn.deterministic = True
       torch.backends.cudnn.benchmark = False
   ```

3. **Stage execution** — follow the exact same pattern as `orchestrator.py:reconstruct()`:
   - Load calibration, discover videos, create undistortion maps and projection models
   - Skip camera `e3v8250` (same as orchestrator)
   - Create stateful objects (tracker, extractor, segmentor)
   - Run each of the 5 stages in order, capturing outputs

4. **Serialization** — after each stage completes, save its output:
   - `golden_detection.pt`: The `detections_per_frame` list. Detection objects contain bbox (list[float]) and confidence (float) — serialize as-is with torch.save.
   - `golden_segmentation.pt`: The `masks_per_frame` list. Contains numpy arrays and CropRegion objects — serialize as-is.
   - `golden_tracking.pt`: The `tracks_per_frame` list. Contains FishTrack objects.
   - `golden_midline_extraction.pt`: The `midline_sets` list. Contains MidlineSet dicts.
   - `golden_triangulation.pt`: The `midlines_3d` list. Contains Midline3D objects.
   - `metadata.pt`: A dict with `seed`, `stop_frame`, `detector_kind`, `max_fish`, `torch_version`, `cuda_version` (or "N/A"), `gpu_name` (or "N/A"), `numpy_version`, `camera_ids` (sorted list), `frame_count`, and `generation_timestamp` (ISO 8601 string).

5. **Logging** — use Python logging to print progress for each stage (stage name, time taken, number of frames/cameras).

6. **Create `tests/golden/.gitkeep`** as an empty file so the directory exists in version control before golden data is generated.

**Important:** The script imports from `aquapose.pipeline.stages` and `aquapose.pipeline.orchestrator` — it reuses the existing v1.0 stage functions directly. Do NOT reimplement stage logic.

**Important:** Masks contain numpy arrays which torch.save handles fine (pickle-based). CropRegion, Detection, FishTrack, Midline3D are all dataclasses/namedtuples — also pickle-compatible.
  </action>
  <verify>
    <automated>cd C:/Users/tucke/PycharmProjects/AquaPose && python -c "import ast; ast.parse(open('scripts/generate_golden_data.py').read()); print('syntax OK')" && python scripts/generate_golden_data.py --help</automated>
  </verify>
  <done>Script exists, parses, shows help with all expected arguments. tests/golden/.gitkeep exists.</done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Generate and commit golden data</name>
  <what-built>Golden data generation script at scripts/generate_golden_data.py. The user must run this script with their local video data and model weights to produce the .pt fixture files, since raw videos and model weights are NOT committed to the repo.</what-built>
  <how-to-verify>
Run the script with your local data paths:

```bash
cd C:/Users/tucke/PycharmProjects/AquaPose
python scripts/generate_golden_data.py \
  --video-dir "C:/Users/tucke/Desktop/Aqua/AquaPose/raw_videos" \
  --calibration "path/to/calibration.json" \
  --stop-frame 30 \
  --detector-kind yolo \
  --yolo-weights "runs/detect/output/yolo_fish/train_v1/weights/best.pt" \
  --unet-weights "C:/Users/tucke/Desktop/Aqua/AquaPose/unet/best_model.pth" \
  --seed 42 \
  --output-dir tests/golden/
```

**Verify:**
1. Script completes without error, printing stage timings
2. `tests/golden/` contains: `golden_detection.pt`, `golden_segmentation.pt`, `golden_tracking.pt`, `golden_midline_extraction.pt`, `golden_triangulation.pt`, `metadata.pt`
3. Total size is ~7-10MB (reasonable for repo commit)
4. Re-running with same arguments produces the same outputs (verify with a quick check: `python -c "import torch; a=torch.load('tests/golden/golden_detection.pt'); b=torch.load('tests/golden/golden_detection.pt'); print('identical')"`)
5. Commit the golden data files as a standalone commit:
   ```bash
   git add tests/golden/
   git commit -m "data(14): commit golden reference outputs from v1.0 pipeline"
   ```

**Note:** The calibration path depends on your local setup. Check `C:/Users/tucke/Desktop/Aqua/` for the AquaCal JSON file.
  </how-to-verify>
  <resume-signal>Type "approved" once golden data is generated and committed, or describe any issues.</resume-signal>
</task>

</tasks>

<verification>
1. `scripts/generate_golden_data.py` exists and runs `--help` without error
2. Script sets deterministic seeds before any computation
3. Script follows exact same stage order as `orchestrator.py:reconstruct()`
4. Each stage output is saved as a separate `.pt` file in `tests/golden/`
5. Environment metadata is recorded in `metadata.pt`
6. Golden data files are committed as a standalone commit
</verification>

<success_criteria>
- Golden data generation script is complete and documented
- All 5 stage outputs + metadata are saved as `.pt` files in `tests/golden/`
- Golden data is committed to the repository as a standalone commit
- Re-running the script with the same inputs produces equivalent outputs
</success_criteria>

<output>
After completion, create `.planning/phases/14-golden-data-and-verification-framework/14-01-SUMMARY.md`
</output>
