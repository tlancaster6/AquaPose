---
phase: 28-e2e-testing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/e2e/test_smoke.py
  - tests/e2e/conftest.py
  - tests/e2e/__init__.py
  - .gitignore
autonomous: false
requirements: [EVAL-01]
must_haves:
  truths:
    - "Synthetic e2e test passes via hatch run test (not @slow)"
    - "Real-data e2e test passes via hatch run test-all on 4-camera subset with ~100 frames"
    - "At least 1 fish produces valid 3D splines spanning 3+ contiguous frames in real-data test"
    - "Reprojection overlay videos saved to tests/e2e/output/ for human review after real-data test"
    - "Pipeline-blocking bugs are fixed during execution; non-blocking bugs documented"
  artifacts:
    - path: "tests/e2e/test_smoke.py"
      provides: "Rewritten e2e tests: synthetic smoke + real-data validation"
    - path: "tests/e2e/conftest.py"
      provides: "Shared fixtures for e2e tests (paths, output dir)"
    - path: ".gitignore"
      provides: "tests/e2e/output/ ignored"
  key_links:
    - from: "tests/e2e/test_smoke.py"
      to: "aquapose.engine.pipeline.PosePipeline"
      via: "In-process pipeline invocation or CLI subprocess"
      pattern: "PosePipeline|aquapose run"
    - from: "tests/e2e/test_smoke.py"
      to: "aquapose.engine.config.load_config"
      via: "Config construction for test runs"
      pattern: "load_config|PipelineConfig"
---

<objective>
Rewrite e2e tests to exercise the current v2.1 5-stage pipeline (Detection -> 2D Tracking -> Association -> Midline -> Reconstruction) on both synthetic and real data. Fix blocking bugs encountered during execution. Document non-blocking issues.

Purpose: Validate that the pipeline is basically functional end-to-end after the v2.1 reorder. This is the first real execution of the full pipeline since Phases 22-27 rewired everything.

Output: Passing e2e tests, reprojection overlay videos for human review, bug log if non-blocking issues found.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/28-e2e-testing/28-CONTEXT.md

@src/aquapose/engine/pipeline.py
@src/aquapose/engine/config.py
@src/aquapose/core/context.py
@src/aquapose/cli.py
@tests/e2e/test_smoke.py
@tools/smoke_test.py

<interfaces>
<!-- Key types and contracts the executor needs -->

From src/aquapose/engine/config.py:
```python
@dataclass(frozen=True)
class PipelineConfig:
    run_id: str
    output_dir: str
    video_dir: str | None
    calibration_path: str | None
    mode: str  # "production", "diagnostic", "synthetic", "benchmark"
    detection: DetectionConfig
    midline: MidlineConfig
    association: AssociationConfig
    tracking: TrackingConfig
    reconstruction: ReconstructionConfig
    synthetic: SyntheticConfig
    lut: LutConfig

@dataclass(frozen=True)
class SyntheticConfig:
    fish_count: int = 3
    frame_count: int = 30
    noise_std: float = 1.0
    seed: int = 42

def load_config(
    run_id: str | None = None,
    config_path: str | Path | None = None,
    cli_overrides: dict[str, Any] | None = None,
) -> PipelineConfig: ...
```

From src/aquapose/engine/pipeline.py:
```python
class PosePipeline:
    def __init__(self, stages: list[Stage], config: PipelineConfig, observers: list[Observer] | None = None): ...
    def run(self) -> PipelineContext: ...

def build_stages(config: PipelineConfig) -> list[Stage]: ...
```

From src/aquapose/core/context.py:
```python
@dataclass
class PipelineContext:
    config: object
    run_id: str
    output_dir: Path | None
    camera_ids: list | None
    detections: list | None
    tracks_2d: dict | None
    tracklet_groups: list | None
    annotated_detections: list | None
    midlines_3d: list | None
```

Pipeline modes from CLI:
- "synthetic": Uses SyntheticConfig (3 fish, 30 frames, seed=42). No real video needed. Requires calibration_path.
- "diagnostic": Real data + observer-generated visualization artifacts.
- "production": Real data, minimal output.
- "benchmark": Real data, timing-focused.

Test video location: C:\Users\tucke\Desktop\Aqua\Videos\test_videos\
Available cameras (4-camera subset): e3v831e, e3v8334, e3v83eb, e3v83f0
Calibration: C:\Users\tucke\Desktop\Aqua\AquaCal\release_calibration\calibration.json

Existing SmokeTestRunner in tools/smoke_test.py invokes pipeline as subprocess via `aquapose run`.
Existing tests/e2e/test_smoke.py wraps SmokeTestRunner -- likely needs full rewrite since it references pre-v2.1 patterns.
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Rewrite e2e tests -- synthetic smoke test + real-data validation test</name>
  <files>
    tests/e2e/test_smoke.py
    tests/e2e/conftest.py
    tests/e2e/__init__.py
    .gitignore
  </files>
  <action>
    **Goal:** Replace the existing test_smoke.py with tests that exercise the v2.1 pipeline directly. Assess whether the existing SmokeTestRunner (tools/smoke_test.py) is salvageable for the new pipeline or whether direct in-process invocation is better (executor discretion per CONTEXT.md).

    **conftest.py** -- shared fixtures:
    - `calibration_path` fixture: session-scoped, returns Path to `C:\Users\tucke\Desktop\Aqua\AquaCal\release_calibration\calibration.json`, skips if not found
    - `test_video_dir` fixture: session-scoped, returns Path to `C:\Users\tucke\Desktop\Aqua\Videos\test_videos\`, skips if not found
    - `e2e_output_dir` fixture: returns `tests/e2e/output/` (create if not exists), for saving artifacts for human review
    - `yolo_weights` fixture: session-scoped, returns Path to YOLO weights (`runs/detect/output/yolo_fish/train_v1/weights/best.pt`), skips if not found
    - `unet_weights` fixture: session-scoped, returns Path to U-Net weights (`C:/Users/tucke/Desktop/Aqua/AquaPose/unet/run2/best_model.pth`), skips if not found

    **test_smoke.py** -- two test classes:

    1. `TestSyntheticSmoke` (NOT marked @slow -- runs in normal test suite):
       - `test_synthetic_pipeline_completes`: Build config with `mode="synthetic"`, default SyntheticConfig (3 fish, ~30 frames, seed=42). Use `load_config` or construct PipelineConfig programmatically. Call `build_stages(config)` then `PosePipeline(stages, config).run()`. Assert no exception (smoke test).
       - `test_synthetic_output_validation`: Same as above but also assert:
         - `context.tracks_2d` is not None and has at least 1 camera with tracklets
         - `context.tracklet_groups` is not None and has at least 1 group
         - `context.midlines_3d` is not None (even if empty list, it should be set)
       - These tests exercise Tracking -> Association -> Reconstruction on known-geometry synthetic inputs.
       - Use `tmp_path` for output_dir (no persistent artifacts for synthetic).

    2. `TestRealData` (marked @slow AND @e2e -- only runs with `hatch run test-all`):
       - Requires: calibration_path, test_video_dir, yolo_weights, unet_weights fixtures
       - `test_real_pipeline_completes`: Build config for 4-camera subset, ~100 frames (stop_frame=100), mode="diagnostic" (to generate reprojection overlays). Assert pipeline completes without exception.
       - `test_real_output_has_3d_splines`: Assert at least 1 fish has 3D splines spanning 3+ contiguous frames. Check `context.midlines_3d` structure.
       - Save artifacts (reprojection videos, any HDF5) to `tests/e2e/output/` for human review.
       - Config should point to the 4-camera test_videos directory and use real YOLO + U-Net weights.

    **.gitignore** -- add `tests/e2e/output/` line to prevent committing large test artifacts.

    **__init__.py** -- keep existing (should already exist, verify has docstring).

    **IMPORTANT bug-fix policy:**
    - If the pipeline crashes during test execution, diagnose and fix the blocking bug inline.
    - If the fix is straightforward (missing import, type error, wrong field name, off-by-one), fix it and continue.
    - If the fix is complex or risky (architectural issue, data corruption), STOP and report to user via checkpoint.
    - Non-blocking issues (warnings, degraded quality, some fish fail) -- log in a comment block at the bottom of test_smoke.py or in a separate `.planning/phases/28-e2e-testing/28-BUGS.md` file.

    **Key constraints from CONTEXT.md:**
    - Synthetic tests must NOT be @slow (run in normal `hatch run test`)
    - Real-data tests MUST be @slow (only `hatch run test-all`)
    - No strict numeric thresholds -- visual judgment for real data
    - Synthetic uses existing `--mode synthetic` with default SyntheticConfig
    - Test artifacts saved to `tests/e2e/output/` (gitignored)
  </action>
  <verify>
    <automated>hatch run test tests/e2e/test_smoke.py -k synthetic -x -v</automated>
  </verify>
  <done>
    - Synthetic smoke test passes (pipeline completes, output fields populated)
    - Real-data test class exists with correct markers (@slow, @e2e)
    - tests/e2e/output/ is gitignored
    - Any blocking bugs encountered are fixed
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Verify real-data e2e test and review visual artifacts</name>
  <files>tests/e2e/output/</files>
  <action>
    Human verifies real-data e2e test output. Claude has already run the tests and generated artifacts in Task 1.
    What was built: End-to-end tests exercising the full v2.1 5-stage pipeline on both synthetic and real data.
    How to verify:
    1. Run: hatch run test-all tests/e2e/test_smoke.py -v (runs both synthetic and real-data tests)
    2. Check test output -- both synthetic and real-data tests should pass
    3. Review reprojection overlay videos in tests/e2e/output/ -- splines should visibly follow fish in at least some frames
    4. If non-blocking bugs were logged, review .planning/phases/28-e2e-testing/28-BUGS.md
    Resume signal: Type "approved" if splines visibly track fish, or describe issues you see.
  </action>
  <verify>
    <automated>hatch run test-all tests/e2e/test_smoke.py -v</automated>
  </verify>
  <done>User confirms reprojection overlays show splines visibly following fish in at least some frames</done>
</task>

</tasks>

<verification>
1. `hatch run test -k synthetic` -- synthetic e2e tests pass in normal test suite
2. `hatch run test-all tests/e2e/ -v` -- all e2e tests pass (including @slow real-data)
3. `tests/e2e/output/` contains reprojection overlay videos after real-data test
4. No pipeline crashes on either synthetic or real data
5. At least 1 fish yields 3D splines spanning 3+ contiguous frames in real-data test
</verification>

<success_criteria>
- Synthetic pipeline test passes without @slow marker (fast CI guard)
- Real-data pipeline test passes on 4-camera subset with ~100 frames
- At least 1 fish produces valid 3D splines spanning 3+ contiguous frames
- Reprojection overlays saved for human review
- Blocking bugs fixed; non-blocking bugs documented
- All tests use current v2.1 pipeline (not legacy SmokeTestRunner if it is outdated)
</success_criteria>

<output>
After completion, create `.planning/phases/28-e2e-testing/28-01-SUMMARY.md`
</output>
