---
phase: 02-segmentation-pipeline
task: verification
total_tasks: 3 plans complete, human verification pending
status: human_needed
last_updated: 2026-02-20T01:27:46.906Z
---

<current_state>
Phase 2 code is COMPLETE — all 3 plans executed, all automated tests pass (49 total: 12 + 21 + 16), all code committed. Phase is now blocked on human verification of 3 items that require real data. The phase verifier scored 3/4 must-haves at code level.

STATE.md is up to date. ROADMAP progress shows Phase 2 at 3/3 plans complete.
</current_state>

<completed_work>

- Plan 02-01 (Wave 1): MOG2 Fish Detector — DONE
  - MOG2Detector class with apply(), detect(), warm_up()
  - Detection dataclass (bbox, mask, area, confidence)
  - Shadow exclusion (threshold at 254), morphological cleanup, min_area filtering
  - 12 unit tests passing
  - Commit: 177b9bc

- Plan 02-02 (Wave 2): SAM2 Pseudo-Labeler + Label Studio — DONE
  - SAMPseudoLabeler with lazy SAM2 loading, box+mask prompts
  - Label Studio export (brush RLE) and import utilities
  - COCO JSON conversion (to_coco_dataset)
  - 21 unit tests passing
  - Commit: 2b13849

- Plan 02-03 (Wave 3): Mask R-CNN Dataset + Training + Pipeline API — DONE
  - CropDataset loading COCO JSON, producing 256x256 crops with augmentation
  - MaskRCNNSegmentor wrapping torchvision maskrcnn_resnet50_fpn_v2 (not Detectron2)
  - Training script: SGD, StepLR, 80/20 split, model checkpointing
  - evaluate() computing mask IoU via pycocotools
  - 16 unit tests passing (including @slow smoke tests)
  - Commit: b87fc08

- Planning artifacts: RESEARCH.md, 3 PLAN.md files, 3 SUMMARY.md files, VERIFICATION.md
</completed_work>

<remaining_work>

3 human verification items (require real aquarium footage):

1. **MOG2 recall measurement** — Run MOG2Detector on representative frames from all 13 cameras. Count detections vs visible fish. Must achieve >= 95% recall. Pay special attention to female fish (low contrast) and stationary subjects.

2. **Label Studio round-trip** — Generate pseudo-labels on sample frames, import tasks JSON into Label Studio project, verify masks display as editable brush annotations, correct a few masks, export and re-import to confirm round-trip.

3. **Mask R-CNN IoU targets** — After completing annotation workflow (step 2), train Mask R-CNN on corrected annotations. Run evaluate() on val set. Must achieve >= 0.90 mean mask IoU overall and >= 0.85 on female-only subset.

After human verification passes: mark phase complete via /gsd:execute-phase 2 (it will detect VERIFICATION.md) or manually update ROADMAP.md.
</remaining_work>

<decisions_made>

- [02-01]: Shadow exclusion via threshold at 254 (MOG2 outputs 127 for shadows, 255 for foreground)
- [02-01]: Detection.mask is full-frame sized (not cropped to bbox) to feed directly into SAM as mask prompt
- [02-02]: SAM2 predictor lazily loaded on first predict() call to avoid GPU allocation on import
- [02-02]: Label Studio uses its own RLE variant (mask2rle from label-studio-converter) not pycocotools RLE
- [02-03]: torchvision maskrcnn_resnet50_fpn_v2 instead of Detectron2 — Detectron2 is unmaintained (v0.6, Oct 2021) and officially unsupported on Windows
- [02-03]: Custom collate_fn with tuple(zip(*batch)) for Mask R-CNN's list-of-dicts format
</decisions_made>

<blockers>
- No code blockers — all automated work is done
- Human verification requires real aquarium footage and GPU for SAM2/Mask R-CNN inference
- SAM2 must be installed separately (not on PyPI — git clone + pip install -e)
</blockers>

<context>
Phase 2 followed a 3-wave sequential dependency chain: MOG2 detector (wave 1) feeds SAM pseudo-labeler (wave 2) which produces annotations for Mask R-CNN training (wave 3). The planning went through a research -> plan -> verify -> revise -> re-verify loop. Checker found 3 warnings on first pass (missing training tests, IoU targets not in must_haves, __init__.py not in files_modified) — all fixed in revision, passed on second verification.

Key architectural note: the pipeline is per-camera, per-frame only. Cross-camera logic (N-fish enforcement, global context) is handled by callers in Phase 4+.

The Detectron2 -> torchvision substitution was the main deviation from CONTEXT.md. Research justified it thoroughly (unmaintained, Windows-incompatible). No locked decision was violated since the implementation library was under Claude's Discretion.
</context>

<next_action>
Start with: /gsd:resume-work

Then either:
1. If you have real aquarium footage ready: run the 3 human verification steps (MOG2 recall, LS round-trip, Mask R-CNN IoU)
2. If not ready for verification yet: proceed to Phase 3 (Fish Mesh Model) which depends only on Phase 1 (already complete), not Phase 2 — can develop in parallel per ROADMAP
</next_action>
