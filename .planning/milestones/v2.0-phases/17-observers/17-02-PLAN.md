# Plan 17-02: HDF5 Export Observer

---
wave: 1
depends_on: []
files_modified:
  - src/aquapose/engine/hdf5_observer.py
  - tests/unit/engine/test_hdf5_observer.py
  - src/aquapose/engine/__init__.py
requirements:
  - OBS-02
autonomous: true
---

## Goal

Implement an HDF5ExportObserver that writes final 3D spline control points and metadata to `outputs.h5` when the pipeline completes, using a frame-major layout. The observer subscribes to PipelineComplete and reads from PipelineContext.

## Context

- **CONTEXT.md decisions**:
  - Two separate files: `outputs.h5` (lean, always written) and `snapshot.h5` (heavy, diagnostic only)
  - This plan covers `outputs.h5` ONLY — snapshot is part of DiagnosticObserver (plan 17-05)
  - `outputs.h5` contains final 3D spline control points only, frame-major layout (`/frames/0001/fish_0`, etc.)
  - Metadata: run ID, config hash, frame count, fish ID list
- **Existing code**: `src/aquapose/io/midline_writer.py` has `Midline3DWriter` with chunked layout under `/midlines/` — this is v1.0 writer. The new observer uses a different frame-major layout per CONTEXT.md
- **PipelineContext.midlines_3d**: `list[dict[int, Spline3D]]` — per-frame dicts mapping fish_id to Spline3D objects
- The observer needs to access PipelineContext. Since Observer.on_event receives Event objects, the observer needs a reference to the context. Pattern: PipelineComplete event already has run_id; the observer stores a reference to the context set via a `set_context` method or captured from the pipeline. Simplest approach: the observer takes `output_dir` in constructor and receives context via a dedicated method `write(context)` called by PosePipeline, OR we pass context in a new event field. **Chosen approach**: Add a `context` field to PipelineComplete event (typed as `object` to avoid circular imports, same pattern as PipelineStart.config). This keeps the observer purely event-driven.

## Must-Haves (Goal-Backward)

1. HDF5ExportObserver satisfies Observer protocol
2. On PipelineComplete, writes `outputs.h5` to the run output directory
3. Frame-major HDF5 layout: `/frames/NNNN/fish_N/control_points` (float32, shape (7,3))
4. Root-level metadata attributes: run_id, config_hash, frame_count, fish_ids (unique sorted list)
5. Unit tests verify HDF5 structure and content from synthetic context data
6. PipelineComplete event gains optional `context` field for observer access

## Tasks

<task id="17-02-T1">
<title>Add context field to PipelineComplete and implement HDF5ExportObserver</title>
<description>
**Step 1: Extend PipelineComplete event**

In `src/aquapose/engine/events.py`, add a `context` field to `PipelineComplete`:
```python
context: object = field(default=None, compare=False)
```
This follows the same pattern as `PipelineStart.config`. The field is typed as `object` to maintain ENG-07 import boundary.

Update `PosePipeline.run()` in `src/aquapose/engine/pipeline.py` to pass the context when emitting PipelineComplete:
```python
self._bus.emit(
    PipelineComplete(
        run_id=self._config.run_id,
        elapsed_seconds=total_elapsed,
        context=context,
    )
)
```

**Step 2: Create HDF5ExportObserver**

Create `src/aquapose/engine/hdf5_observer.py`:

- Class `HDF5ExportObserver` with `on_event(self, event: Event) -> None`
- Constructor: `__init__(self, output_dir: str | Path)` — stores output directory
- On `PipelineComplete`:
  - Extract `context` from event (skip if None)
  - Extract `midlines_3d` from context (skip if None or not a list)
  - Write `{output_dir}/outputs.h5` with frame-major layout
- HDF5 layout:
  - Group `/frames/NNNN/` for each frame (zero-padded 4 digits)
  - Subgroup `/frames/NNNN/fish_N/` for each fish in that frame
  - Dataset `control_points`: float32, shape (7, 3) — spline control points
  - Dataset `arc_length`: float32, scalar
  - Root attributes: `run_id` (str), `frame_count` (int), `fish_ids` (sorted unique int array)
  - Root attribute `config_hash`: MD5 hex of serialized config string (from PipelineStart event, captured if received)
- On `PipelineStart`: capture `config` object and compute config_hash via `hashlib.md5` on `serialize_config(config)` (import serialize_config locally to avoid circular imports; guard with try/except for robustness)
- Use `h5py.File` context manager for safe writes

Add `HDF5ExportObserver` to `src/aquapose/engine/__init__.py` exports and `__all__`.
</description>
</task>

<task id="17-02-T2">
<title>Unit tests for HDF5ExportObserver</title>
<description>
Create `tests/unit/engine/test_hdf5_observer.py`.

Tests:
1. `test_hdf5_observer_satisfies_protocol` — `isinstance(HDF5ExportObserver(tmp_path), Observer)` is True
2. `test_hdf5_writes_on_pipeline_complete` — create observer with tmp_path, fire PipelineComplete with a mock context containing 2 frames x 2 fish with numpy control_points arrays. Assert `outputs.h5` exists and contains `/frames/0000/fish_0/control_points` with correct shape (7,3)
3. `test_hdf5_frame_major_layout` — verify all expected frame/fish groups exist and dataset values match input
4. `test_hdf5_metadata_attributes` — verify root attrs: run_id, frame_count, fish_ids
5. `test_hdf5_config_hash` — fire PipelineStart with config, then PipelineComplete; verify config_hash root attr is non-empty hex string
6. `test_hdf5_skips_if_no_context` — fire PipelineComplete without context field; assert no file written, no error raised
7. `test_hdf5_empty_frames` — fire with 0 frames; assert file written with frame_count=0

Use simple mock objects with `.control_points` (numpy array shape (7,3)) and `.arc_length` (float) attributes for the Spline3D stand-ins. Use `h5py.File` to read back and verify.
</description>
</task>

## Verification

```bash
hatch run test tests/unit/engine/test_hdf5_observer.py -v
hatch run test tests/unit/engine/test_pipeline.py -v  # ensure PipelineComplete context field doesn't break existing tests
hatch run check
```

- [ ] All tests pass
- [ ] `outputs.h5` has frame-major layout with correct control point data
- [ ] Metadata attributes present and correct
- [ ] Existing pipeline tests still pass with new context field on PipelineComplete
- [ ] No stage code was modified
