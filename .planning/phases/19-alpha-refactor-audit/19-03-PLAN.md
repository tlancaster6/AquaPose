---
phase: 19-alpha-refactor-audit
plan: 03
type: execute
wave: 2
depends_on: [19-01, 19-02]
files_modified:
  - .planning/phases/19-alpha-refactor-audit/19-AUDIT.md
autonomous: true
requirements: [AUDIT]

must_haves:
  truths:
    - "The DoD gate check (guidebook section 16) is evaluated against the actual codebase"
    - "Codebase health findings are cataloged with 3-tier severity"
    - "Import boundary violations are documented from Plan 01 output"
    - "Verification run results are documented from Plan 02 output"
    - "All findings are organized in a structured audit report"
  artifacts:
    - path: ".planning/phases/19-alpha-refactor-audit/19-AUDIT.md"
      provides: "Complete structured audit report for Phase 20 remediation"
  key_links:
    - from: ".planning/phases/19-alpha-refactor-audit/19-AUDIT.md"
      to: ".planning/phases/20-post-refactor-loose-ends/"
      via: "findings inform Phase 20 planning"
      pattern: "remediation"
---

<objective>
Perform the comprehensive audit of the v2.0 Alpha refactor and produce the structured 19-AUDIT.md report.

Purpose: This is the core deliverable of Phase 19 — a structured assessment of whether the refactor faithfully implements the guidebook's architectural vision. The report catalogs findings by severity for Phase 20 remediation. It does NOT fix anything — it diagnoses.

Output: 19-AUDIT.md with all required sections.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/19-alpha-refactor-audit/19-CONTEXT.md
@.planning/alpha_refactor_guidebook.md
@.planning/phases/19-alpha-refactor-audit/19-01-SUMMARY.md
@.planning/phases/19-alpha-refactor-audit/19-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: DoD gate check, structural audit, and numerical verification</name>
  <files>.planning/phases/19-alpha-refactor-audit/19-AUDIT.md (partial)</files>
  <action>
Perform a systematic audit. Write findings directly into 19-AUDIT.md as you go.

**Section 1: DoD Gate Check (guidebook Section 16)**

Evaluate each DoD criterion against the actual codebase:

| Criterion | How to check |
|-----------|-------------|
| Exactly one canonical pipeline entrypoint | Grep for PosePipeline instantiation — should be exactly one path from CLI |
| All scripts invoke PosePipeline | Check scripts/ for any direct stage calls |
| `aquapose run` produces 3D midlines | Verify CLI entrypoint exists and wires to pipeline |
| Diagnostic functionality via observers | Check DiagnosticObserver exists and is wired in diagnostic mode |
| Synthetic mode runs through pipeline | Check SyntheticStageAdapter or equivalent exists |
| Timing, HDF5, viz, diagnostics as observers | Verify all 4 observer types exist in engine/ |
| No stage imports dev tooling | Run import boundary checker from Plan 01 |
| CLI is thin wrapper | Measure cli.py LOC vs engine/ LOC — CLI should be minimal |
| No script calls stage functions directly | Grep scripts/ for direct stage imports |

For each: mark PASS/FAIL with evidence (file paths, line numbers).

**Section 2: Structural Rules**

Run the import boundary checker from Plan 01 and document results:
- Import boundary violations (IB-001 through IB-004)
- Structural rule violations (SR-001, SR-002)
- Document each violation with file, line, severity

**Section 3: Verification Run Results**

Incorporate results from Plan 02 smoke tests:
- Which modes passed/failed
- Which backends passed/failed
- Reproducibility result
- Any errors or warnings

**Section 4: Numerical Verification**

Run the existing regression tests:
```bash
hatch run test tests/regression/ -v
```
- Document pass/fail for each regression test
- Missing coverage for any stage is Warning severity
- Failures are Critical severity

Assign severity to each finding:
- **Critical**: Architectural violation that must be fixed (e.g., import boundary violation, DoD failure)
- **Warning**: Non-ideal but functional (e.g., missing test coverage, minor structural deviation)
- **Info**: Cosmetic or minor (e.g., naming inconsistency, stale comment)
  </action>
  <verify>
    <automated>cd C:/Users/tucke/PycharmProjects/AquaPose && test -f .planning/phases/19-alpha-refactor-audit/19-AUDIT.md && echo "AUDIT.md exists"</automated>
  </verify>
  <done>Sections 1-4 of 19-AUDIT.md are populated with evidence-based findings and severity ratings.</done>
</task>

<task type="auto">
  <name>Task 2: Codebase health audit and remediation summary</name>
  <files>.planning/phases/19-alpha-refactor-audit/19-AUDIT.md (complete)</files>
  <action>
Continue building 19-AUDIT.md with the remaining sections.

**Section 5: Codebase Health**

Systematically scan for each category listed in CONTEXT.md:

1. **Dead code candidates** — Files/functions that appear unused:
   - Search for modules imported nowhere
   - Search for functions defined but never called (grep for def, then grep for usage)
   - Focus on: `src/aquapose/pipeline/` (old pipeline dir), any `__pycache__` artifacts, unused utilities
   - Severity: Info

2. **Repeated patterns candidates for functionalization:**
   - Look for duplicated code blocks across stages (e.g., calibration loading, config access patterns)
   - Severity: Info

3. **Bloated modules candidates for splitting:**
   - Identify files > 300 LOC that could be split
   - Severity: Info

4. **Legacy scripts that won't work with new codebase:**
   - Check `scripts/` (non-legacy): `build_training_data.py`, `generate_golden_data.py`, `organize_yolo_dataset.py`, `sample_yolo_frames.py`, `train_yolo.py`
   - Do they import old modules? Would they work with the current codebase?
   - Severity: Warning if broken, Info if functional

5. **Guidebook vs actual structure deviations:**
   - Compare guidebook Section 4 layout to actual `src/aquapose/` layout
   - Flag extra directories (visualization/, synthetic/, io/, utils/, pipeline/, mesh/, initialization/)
   - Flag missing directories if any
   - Severity: Info (flag only per CONTEXT.md)

6. **Unused imports and dependencies in pyproject.toml:**
   - Check for imports in pyproject.toml dependencies that are not used in src/
   - Severity: Info

7. **Stale test fixtures:**
   - Grep tests/ for references to old patterns (e.g., old module names, deprecated fixtures)
   - Severity: Info

8. **Inconsistent naming:**
   - Old vocabulary vs new engine vocabulary (e.g., "orchestrator" vs "pipeline", "segmentation" vs "midline")
   - Severity: Info

9. **TODO/FIXME/HACK comment catalog:**
   - `grep -rn "TODO\|FIXME\|HACK" src/ tests/`
   - Categorize as actionable vs stale
   - Severity: Info

**Section 6: Findings by Severity**

Aggregate all findings from Sections 1-5 into severity buckets:
- Critical: [count] findings
- Warning: [count] findings
- Info: [count] findings

Each finding gets a unique ID (e.g., AUD-001, AUD-002) for Phase 20 reference.

**Section 7: Remediation Summary**

For each Critical and Warning finding:
- What needs to be done
- Estimated effort (small/medium/large)
- Suggested Phase 20 grouping

Note: This does NOT populate Phase 20 plans — it provides structured input for the user to review and decide what to address.

**Final format of 19-AUDIT.md:**
```markdown
# Alpha Refactor Audit Report

## Summary
- Total findings: N
- Critical: X | Warning: Y | Info: Z
- DoD Gate: PASS/FAIL

## 1. DoD Gate Check
## 2. Structural Rules
## 3. Verification Run Results
## 4. Numerical Verification
## 5. Codebase Health
## 6. Findings by Severity
## 7. Remediation Summary
```
  </action>
  <verify>
    <automated>cd C:/Users/tucke/PycharmProjects/AquaPose && python -c "
content = open('.planning/phases/19-alpha-refactor-audit/19-AUDIT.md').read()
sections = ['DoD Gate Check', 'Structural Rules', 'Verification Run Results', 'Numerical Verification', 'Codebase Health', 'Findings by Severity', 'Remediation Summary']
missing = [s for s in sections if s not in content]
print(f'Missing sections: {missing}' if missing else 'All 7 sections present')
"</automated>
  </verify>
  <done>19-AUDIT.md is complete with all 7 sections. Each finding has a unique ID, severity, and evidence. Remediation summary provides structured input for Phase 20 planning.</done>
</task>

</tasks>

<verification>
1. 19-AUDIT.md exists and contains all 7 required sections
2. Every DoD criterion from guidebook Section 16 is evaluated with PASS/FAIL
3. Import boundary checker results are incorporated
4. Smoke test results are incorporated
5. Regression test results are documented
6. Findings have unique IDs and 3-tier severity
7. Remediation summary covers all Critical and Warning findings
</verification>

<success_criteria>
- Complete audit report at `.planning/phases/19-alpha-refactor-audit/19-AUDIT.md`
- DoD gate evaluated with evidence
- All codebase health categories from CONTEXT.md covered
- Findings organized by severity with unique IDs
- Remediation summary provides actionable input for Phase 20
- Report is comprehensive but not prescriptive (flags, doesn't fix)
</success_criteria>

<output>
After completion, create `.planning/phases/19-alpha-refactor-audit/19-03-SUMMARY.md`
</output>
