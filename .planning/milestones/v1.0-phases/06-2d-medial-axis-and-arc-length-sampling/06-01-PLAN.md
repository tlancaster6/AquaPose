---
phase: 06-2d-medial-axis-and-arc-length-sampling
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - src/aquapose/reconstruction/__init__.py
  - src/aquapose/reconstruction/midline.py
  - tests/unit/test_midline.py
autonomous: true
requirements:
  - RECON-01
  - RECON-02
must_haves:
  truths:
    - "Given a binary fish mask, the system produces an ordered 15-point 2D midline with half-widths"
    - "Spurious skeleton branches are pruned to a single head-to-tail path via longest-path BFS"
    - "Arc-length resampling produces exactly 15 evenly-spaced points regardless of skeleton pixel count"
    - "Crop-space midline coordinates are correctly transformed to full-frame pixel coordinates including half-width scaling"
    - "Edge cases (too-small masks, boundary-clipped masks, degenerate skeletons) are skipped gracefully without crashing"
    - "Head-to-tail orientation is determined from 3D velocity with inheritance for ambiguous frames and capped back-correction"
  artifacts:
    - path: "src/aquapose/reconstruction/midline.py"
      provides: "Midline2D dataclass, MidlineExtractor class, all pipeline helpers"
      contains: "class Midline2D"
    - path: "src/aquapose/reconstruction/__init__.py"
      provides: "Public exports for reconstruction package"
      exports: ["Midline2D", "MidlineExtractor"]
    - path: "tests/unit/test_midline.py"
      provides: "Unit tests for midline extraction pipeline"
      contains: "def test_"
    - path: "pyproject.toml"
      provides: "scikit-image dependency declaration"
      contains: "scikit-image"
  key_links:
    - from: "src/aquapose/reconstruction/midline.py"
      to: "skimage.morphology.skeletonize"
      via: "import"
      pattern: "from skimage.morphology import skeletonize"
    - from: "src/aquapose/reconstruction/midline.py"
      to: "src/aquapose/segmentation/crop.py"
      via: "CropRegion for coordinate transform"
      pattern: "from aquapose.segmentation.crop import CropRegion"
    - from: "src/aquapose/reconstruction/midline.py"
      to: "src/aquapose/tracking/tracker.py"
      via: "FishTrack for velocity-based orientation"
      pattern: "from aquapose.tracking.tracker import FishTrack"
---

<objective>
Implement the full 2D medial axis extraction and arc-length sampling pipeline as `src/aquapose/reconstruction/midline.py`.

Purpose: This is the bridge between raw segmentation masks and structured midline correspondences that Phase 7's multi-view triangulation will consume. Without stable, consistently-ordered 2D midlines, triangulation cannot establish cross-view point correspondences.

Output: A `MidlineExtractor` class that takes per-camera masks + crop regions + FishTrack objects and produces `dict[int, dict[str, Midline2D]]` — 15-point midlines in full-frame coordinates with half-widths and consistent head-to-tail orientation.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-2d-medial-axis-and-arc-length-sampling/06-RESEARCH.md
@src/aquapose/tracking/tracker.py
@src/aquapose/segmentation/crop.py
@src/aquapose/segmentation/detector.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add scikit-image dependency and create reconstruction package with core pipeline helpers</name>
  <files>
    pyproject.toml
    src/aquapose/reconstruction/__init__.py
    src/aquapose/reconstruction/midline.py
  </files>
  <action>
1. Add `"scikit-image>=0.21"` to the `[project] dependencies` list in `pyproject.toml`.

2. Create `src/aquapose/reconstruction/__init__.py` exporting `Midline2D` and `MidlineExtractor` from `.midline`.

3. Create `src/aquapose/reconstruction/midline.py` with:

**Data structure:**
- `Midline2D` dataclass with fields: `points` (ndarray shape (15,2) float32 full-frame pixels), `half_widths` (ndarray shape (15,) float32), `fish_id` (int), `camera_id` (str), `frame_index` (int), `is_head_to_tail` (bool, default True).

**Private helper functions (all in this file):**

- `_check_skip_mask(mask: np.ndarray, min_area: int = 300) -> str | None` — Returns skip reason if mask area < min_area OR mask has nonzero pixels touching any edge of the crop. Returns None if mask is valid.

- `_adaptive_smooth(mask: np.ndarray) -> np.ndarray` — Morphological closing then opening with adaptive elliptical kernel. Kernel radius = `max(3, int(minor_axis_length) // 8)` using `skimage.measure.regionprops` for minor axis. Input/output: uint8 binary mask.

- `_skeleton_and_widths(smooth_mask: np.ndarray) -> tuple[np.ndarray, np.ndarray]` — Returns `(skeleton_bool, distance_transform)` via `skimage.morphology.skeletonize` and `scipy.ndimage.distance_transform_edt` on the smoothed boolean mask.

- `_longest_path_bfs(skel: np.ndarray) -> list[tuple[int, int]]` — Two-pass BFS: find endpoints via `scipy.ndimage.convolve` with 3x3 kernel (mode='constant'), BFS from any endpoint to find farthest point, BFS again from that to find the true farthest point, reconstruct path. Returns ordered (row, col) list. Uses 8-connectivity via set membership lookup. Returns [] if skeleton is empty.

- `_resample_arc_length(path_yx: list[tuple[int, int]], dt: np.ndarray, n_points: int = 15) -> tuple[np.ndarray, np.ndarray]` — Compute cumulative arc-length along path, normalize to [0,1], interpolate x, y, and half-width at n_points evenly-spaced positions using `scipy.interpolate.interp1d`. Returns `(xy_crop, half_widths)` where xy_crop is (N,2) float32 in (x,y) crop-space and half_widths is (N,) float32.

- `_crop_to_frame(xy_crop: np.ndarray, half_widths: np.ndarray, crop_region: CropRegion, crop_h: int, crop_w: int) -> tuple[np.ndarray, np.ndarray]` — Scale+translate xy from crop-space to full-frame using CropRegion fields. Scale half-widths by average of x and y scale factors: `(scale_x + scale_y) / 2.0`. Returns (xy_frame, hw_frame) both float32.

- `_orient_midline(xy_frame: np.ndarray, track: FishTrack, camera_id: str, projection_models: dict, fps: float, body_length_m: float) -> tuple[np.ndarray, bool]` — Project 3D predicted head position (centroid + velocity_unit * half_body_length) into camera using RefractiveProjectionModel. Compare distance to both endpoints. If speed < threshold (0.5 body-lengths/sec converted to m/frame via fps), return (xy_frame, False) for inheritance. Otherwise return (oriented_xy, True). NOTE: the projection_models dict maps camera_id to a projection model with a `project()` method — use the interface from `aquapose.calibration.projection`.

**Stateful class:**

- `MidlineExtractor` class:
  - Constructor: `__init__(self, n_points: int = 15, min_area: int = 300, fps: float = 30.0, body_length_m: float = 0.15, velocity_threshold_bls: float = 0.5)` — stores config, initializes empty `_orientations: dict[int, bool]` (fish_id → last known is_head_first), `_back_correction_buffers: dict[int, list[tuple[int, str, Midline2D]]]` (fish_id → list of (frame_idx, camera_id, midline) awaiting orientation), `_back_correction_frame_counts: dict[int, int]` (fish_id → frames since track start).

  - `extract_midlines(self, tracks: list[FishTrack], masks_per_camera: dict[str, list[np.ndarray]], crop_regions_per_camera: dict[str, list[CropRegion]], detections_per_camera: dict[str, list], projection_models: dict, frame_index: int) -> dict[int, dict[str, Midline2D]]`:
    - For each track, iterate its `camera_detections` (camera_id → detection_index).
    - Look up the mask and crop_region from `masks_per_camera[camera_id][det_idx]` and `crop_regions_per_camera[camera_id][det_idx]`.
    - Run pipeline: check_skip → smooth → skeleton_and_widths → check skeleton length ≥ n_points → longest_path_bfs → resample → crop_to_frame → orient.
    - Handle orientation inheritance: if `_orient_midline` returns `is_established=False`, check `_orientations[fish_id]` for previous orientation. If exists, flip if previous was head-first but current endpoint order disagrees. If no previous exists (first frames), store in back-correction buffer.
    - Handle back-correction: when orientation IS first established for a fish_id, flip all buffered midlines if the established direction differs from the arbitrary first-frame assignment. Cap at 30 frames or `int(fps)` frames (whichever is less). After cap, discard buffer even if orientation was never established.
    - Increment `_back_correction_frame_counts[fish_id]` each frame. When count exceeds cap, commit buffer contents as-is and clear.
    - Return `dict[int, dict[str, Midline2D]]` — only includes cameras where midline extraction succeeded.
  </action>
  <verify>
    Run `hatch run python -c "from aquapose.reconstruction import Midline2D, MidlineExtractor; print('OK')"` — should print OK without import errors.
    Run `hatch run lint` and `hatch run typecheck` — no errors in new files.
  </verify>
  <done>
    - `pyproject.toml` includes `scikit-image>=0.21`
    - `src/aquapose/reconstruction/__init__.py` exports Midline2D and MidlineExtractor
    - `src/aquapose/reconstruction/midline.py` contains all helpers and the MidlineExtractor class
    - All functions have Google-style docstrings and type hints
    - Module imports successfully in hatch env
  </done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for midline extraction pipeline</name>
  <files>
    tests/unit/test_midline.py
  </files>
  <action>
Create `tests/unit/test_midline.py` with comprehensive tests using synthetic masks (no real data needed):

**Helper fixtures:**
- `_make_ellipse_mask(h, w, center, axes, angle=0) -> np.ndarray` — draws a filled ellipse on a uint8 array using `cv2.ellipse`. This simulates a fish-shaped mask.
- `_make_long_mask(h=128, w=128) -> np.ndarray` — creates a horizontally elongated ellipse (axes ~50x10) centered in a 128x128 crop. Represents a typical side-view fish.
- `_make_round_mask(h=64, w=64) -> np.ndarray` — creates a nearly circular blob (axes ~15x14). Represents a head-on view that should produce a degenerate skeleton.
- `_make_tiny_mask(h=64, w=64) -> np.ndarray` — creates a very small blob (area < 300). Should be skipped.
- `_make_boundary_mask(h=64, w=64) -> np.ndarray` — creates a mask touching the top edge. Should be skipped.
- A mock `FishTrack` fixture with configurable velocity and positions.
- A simple `CropRegion` fixture (e.g., x1=100, y1=200, x2=300, y2=400, frame_h=1200, frame_w=1600).

**Test cases:**

1. `test_check_skip_mask_valid` — long mask passes, returns None.
2. `test_check_skip_mask_too_small` — tiny mask returns skip reason containing "too small".
3. `test_check_skip_mask_boundary_clipped` — boundary mask returns skip reason containing "boundary".
4. `test_adaptive_smooth_preserves_shape` — smoothed long mask still has nonzero pixels, area is within 50% of original.
5. `test_skeleton_produces_thin_path` — skeleton of smoothed long mask is 1-pixel wide (max neighbor count ≤ 2 for non-junction pixels), and has ≥15 pixels.
6. `test_longest_path_bfs_returns_ordered_path` — on a T-shaped synthetic skeleton (manually constructed bool array), BFS returns the longest arm, ignoring the branch.
7. `test_longest_path_bfs_empty_skeleton` — all-zero skeleton returns [].
8. `test_resample_arc_length_count` — resampled output has exactly 15 points and 15 half-widths.
9. `test_resample_arc_length_endpoints` — first point is near path start, last point is near path end (within 2px).
10. `test_crop_to_frame_transform` — given a known CropRegion and crop dimensions, verify that (0,0) maps to (x1,y1) and (crop_w, crop_h) maps to (x2, y2). Also verify half-widths are scaled by average scale factor.
11. `test_crop_to_frame_with_resize` — when crop_h != crop_region.height (simulating U-Net 128x128 resize), verify scaling is correct.
12. `test_extract_midlines_full_pipeline` — create a MidlineExtractor, call extract_midlines with a single track claiming one camera, a long ellipse mask, a simple CropRegion, and a mock projection model. Verify output dict has the fish_id key, camera_id key, and Midline2D with 15 points in frame coordinates.
13. `test_extract_midlines_skips_small_mask` — same as above but with a tiny mask. Output dict should have the fish_id key but no camera entries (or fish_id absent entirely).
14. `test_orientation_inheritance` — call extract_midlines twice: first frame with high velocity (orientation established), second frame with near-zero velocity. Verify second frame inherits first frame's orientation (point 0 is on the same side).
15. `test_back_correction_cap` — create extractor, call 35 times with zero velocity (never established). Verify the buffer is cleared after 30 frames (no memory leak, midlines are returned with `is_head_to_tail=False`).

For the mock projection model, create a simple class with a `project(point_3d)` method that returns a 2D array (e.g., orthographic projection dropping Z).

All tests should run without GPU, real images, or real calibration data.
  </action>
  <verify>
    Run `hatch run test tests/unit/test_midline.py -v` — all tests pass.
    Run `hatch run lint tests/unit/test_midline.py` — no lint errors.
  </verify>
  <done>
    - All 15 test cases pass
    - Tests use only synthetic data (no real images, no GPU)
    - Edge cases (skip conditions, degenerate skeletons, back-correction cap) are covered
    - Full pipeline test verifies end-to-end from mask to Midline2D in frame coordinates
  </done>
</task>

</tasks>

<verification>
1. `hatch run python -c "from aquapose.reconstruction import Midline2D, MidlineExtractor"` succeeds
2. `hatch run test tests/unit/test_midline.py -v` — all tests pass
3. `hatch run lint` — no errors in new files
4. `hatch run typecheck` — no type errors in new files
5. Verify that a synthetic ellipse mask produces exactly 15 midline points with non-zero half-widths
6. Verify that boundary-clipped and too-small masks are skipped without errors
</verification>

<success_criteria>
- RECON-01 satisfied: morphological smoothing + skeletonize + longest-path BFS pruning produces ordered midlines with half-widths from distance transform
- RECON-02 satisfied: arc-length resampling produces 15 fixed-size points with crop-to-frame coordinate transform
- All edge cases handled per CONTEXT.md decisions (too small, boundary-clipped, degenerate, single-camera)
- Head-to-tail orientation via 3D velocity with inheritance and capped back-correction
- Unit tests pass without GPU or real data
</success_criteria>

<output>
After completion, create `.planning/phases/06-2d-medial-axis-and-arc-length-sampling/06-01-SUMMARY.md`
</output>
