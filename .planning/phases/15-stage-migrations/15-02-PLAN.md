---
phase: 15-stage-migrations
plan: 02
type: execute
wave: 2
depends_on: [15-01]
files_modified:
  - src/aquapose/core/midline/__init__.py
  - src/aquapose/core/midline/types.py
  - src/aquapose/core/midline/backends/__init__.py
  - src/aquapose/core/midline/backends/segment_then_extract.py
  - src/aquapose/core/midline/backends/direct_pose.py
  - src/aquapose/core/midline/stage.py
  - src/aquapose/engine/config.py
  - tests/unit/core/midline/__init__.py
  - tests/unit/core/midline/test_midline_stage.py
autonomous: true
requirements: [STG-02]

must_haves:
  truths:
    - MidlineStage satisfies engine.stages.Stage protocol via structural typing
    - MidlineStage.run(context) reads context.detections, runs U-Net segmentation then skeletonization+BFS midline extraction, populates context.annotated_detections
    - Segment-then-extract backend is fully implemented — U-Net segmentation + adaptive smoothing + skeletonize + BFS + arc-length resample + crop-to-frame
    - Direct pose estimation backend raises NotImplementedError (stub proving the registry pattern)
    - U-Net model loads eagerly at construction time; clear error if weights path invalid
    - No imports from engine/ in any core/midline/ module
  artifacts:
    - src/aquapose/core/midline/__init__.py
    - src/aquapose/core/midline/types.py
    - src/aquapose/core/midline/stage.py
    - src/aquapose/core/midline/backends/segment_then_extract.py
    - src/aquapose/core/midline/backends/direct_pose.py
    - tests/unit/core/midline/test_midline_stage.py
  key_links:
    - MidlineStage reads PipelineContext.detections (from Stage 1)
    - MidlineStage writes PipelineContext.annotated_detections
    - Uses existing aquapose.segmentation.model.UNetSegmentor for mask prediction
    - Uses existing aquapose.reconstruction.midline.MidlineExtractor for midline extraction
    - Backend selected via config.midline section
---

<objective>
Port the Midline stage (Stage 2) as a pure Stage Protocol implementor in core/midline/.

Purpose: The Midline stage subsumes what v1.0 called "segmentation" and "midline extraction" into a single segment-then-extract backend. It reads detection bounding boxes from Stage 1, crops and segments each detection via U-Net, then extracts 15-point 2D midlines with half-widths via skeletonization + BFS pruning.

Output: A MidlineStage class in core/midline/ that satisfies the Stage Protocol, uses the segment-then-extract backend, and populates PipelineContext.annotated_detections.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-stage-migrations/15-CONTEXT.md

@src/aquapose/engine/stages.py
@src/aquapose/engine/config.py
@src/aquapose/pipeline/stages.py (v1.0 run_segmentation and run_midline_extraction — port this behavior)
@src/aquapose/pipeline/orchestrator.py (v1.0 wiring — shows how segmentation and midline extraction chain)
@src/aquapose/segmentation/model.py (UNetSegmentor)
@src/aquapose/segmentation/crop.py (compute_crop_region, extract_crop, CropRegion)
@src/aquapose/reconstruction/midline.py (MidlineExtractor, Midline2D)
@src/aquapose/segmentation/detector.py (Detection dataclass)

<interfaces>
<!-- Engine contracts -->
From src/aquapose/engine/stages.py:
```python
@dataclass
class PipelineContext:
    detections: list[dict[str, list]] | None = None           # Stage 1 output (input to this stage)
    annotated_detections: list[dict[str, list]] | None = None  # Stage 2 output (this stage writes)
```

From src/aquapose/engine/config.py:
```python
@dataclass(frozen=True)
class MidlineConfig:
    confidence_threshold: float = 0.5
    weights_path: str | None = None
```

<!-- Computation modules used -->
From src/aquapose/segmentation/model.py:
```python
class UNetSegmentor:
    def __init__(self, weights_path=None, confidence_threshold=0.5): ...
    def segment(self, crops, crop_regions) -> list[list[SegmentResult]]: ...
```

From src/aquapose/segmentation/crop.py:
```python
@dataclass
class CropRegion:
    x1: int; y1: int; x2: int; y2: int
    frame_w: int; frame_h: int
    @property
    def width(self) -> int: ...
    @property
    def height(self) -> int: ...

def compute_crop_region(bbox, frame_h, frame_w) -> CropRegion: ...
def extract_crop(frame, region) -> np.ndarray: ...
```

From src/aquapose/reconstruction/midline.py:
```python
@dataclass
class Midline2D:
    points: np.ndarray    # shape (N, 2), float32
    half_widths: np.ndarray  # shape (N,), float32
    fish_id: int
    camera_id: str
    frame_index: int
    is_head_to_tail: bool = False

class MidlineExtractor:
    def __init__(self, n_points=15, min_area=300): ...
    def extract_midlines(self, tracks, masks_per_camera, crop_regions_per_camera,
                         detections_per_camera, frame_index) -> dict[int, dict[str, Midline2D]]: ...
```

<!-- v1.0 behavior to preserve -->
From pipeline/stages.py run_segmentation:
- Re-reads video frames (detection stage does not store raw frames)
- Crops each detection bbox, runs UNetSegmentor on all crops per camera
- Returns list[dict[str, list[tuple[np.ndarray, CropRegion]]]]

From pipeline/stages.py run_midline_extraction:
- Takes tracks, masks, detections
- For each tracked fish in each camera, extracts midline from mask+crop
- Returns list[MidlineSet] where MidlineSet = dict[int, dict[str, Midline2D]]
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create core/midline/ module with segment-then-extract backend and stage</name>
  <files>
    src/aquapose/core/midline/__init__.py
    src/aquapose/core/midline/types.py
    src/aquapose/core/midline/backends/__init__.py
    src/aquapose/core/midline/backends/segment_then_extract.py
    src/aquapose/core/midline/backends/direct_pose.py
    src/aquapose/core/midline/stage.py
    src/aquapose/engine/config.py
  </files>
  <action>
Create the core/midline/ package:

1. **types.py** — Re-export `Midline2D` from `aquapose.reconstruction.midline` and `CropRegion` from `aquapose.segmentation.crop`. Define any stage-specific types if needed (e.g., an AnnotatedDetection type that bundles a Detection with its midline and mask data — or just use the existing Detection objects enriched with midline attributes).

2. **backends/__init__.py** — Backend registry. `get_backend(kind: str, **kwargs)` factory. Supports "segment_then_extract" (default) and "direct_pose" (stub). Raise ValueError for unknown.

3. **backends/segment_then_extract.py** — The main backend. This class:
   - Constructor accepts `weights_path`, `confidence_threshold`, `n_points=15`, `min_area=300`
   - Creates UNetSegmentor and MidlineExtractor at construction time (eager loading, fail-fast)
   - Exposes `process_frame(frame_idx, frame_dets, frames, camera_ids) -> dict[str, list]` that:
     a) Computes crop regions from detection bboxes
     b) Extracts and segments crops via UNetSegmentor
     c) Returns annotated detections (detections enriched with mask/crop/midline data)
   - The segment-then-extract backend combines v1.0's run_segmentation + run_midline_extraction into a single per-frame operation.

   IMPORTANT: In v1.0, segmentation and midline extraction were separate stages with tracking in between. In the new model, the Midline stage runs BEFORE tracking. This means it cannot use track assignments to route masks to fish. Instead, it must annotate ALL detections with midlines (per-detection, not per-track). The annotated_detections output is: per-frame, per-camera, list of detections each enriched with midline points and half-widths.

   The actual data flow change: v1.0 extracted midlines only for tracked fish. The new Midline stage extracts midlines for ALL detections. Downstream stages (Association, Tracking) can use these midlines.

4. **backends/direct_pose.py** — Stub backend. Constructor and process_frame both raise NotImplementedError with message explaining this is a planned alternative backend.

5. **stage.py** — `MidlineStage` class satisfying Stage Protocol:
   - Constructor: accepts `video_dir: str | Path`, `calibration_path: str | Path`, `weights_path: str | None = None`, `confidence_threshold: float = 0.5`, `backend: str = "segment_then_extract"`, `skip_camera_id: str = "e3v8250"`, `device: str = "cuda"`, and other params
   - Loads calibration/undistortion at construction (same as DetectionStage — consider shared utility)
   - Creates the selected backend
   - `run(self, context)`:
     - Reads context.detections and context.camera_ids (from Stage 1)
     - Opens VideoSet to re-read frames (same pattern as v1.0)
     - For each frame, calls backend.process_frame() to produce annotated detections
     - Sets context.annotated_detections (same structure as detections but each Detection now has midline data attached)
     - Returns context

   CRITICAL: core/midline/ must NOT import from engine/. Use TYPE_CHECKING guard for PipelineContext.

6. **__init__.py** — Export MidlineStage, Midline2D.

7. **engine/config.py** — Add `backend: str = "segment_then_extract"` field to MidlineConfig. Add `n_points: int = 15` and `min_area: int = 300`. Update load_config to handle these.

DESIGN NOTE on annotated_detections structure: Each element of annotated_detections is the same shape as detections (per-frame dict of camera->list), but each detection in the list is augmented with midline information. The simplest approach: keep Detection objects as-is, and store midlines alongside in a parallel structure, or create a new AnnotatedDetection wrapper. Choose the approach that preserves v1.0 behavior most faithfully while being clean. Document the chosen structure clearly in types.py.

Record any v1.0 quirks preserved in the bug ledger.
  </action>
  <verify>
    <automated>hatch run python -c "from aquapose.core.midline import MidlineStage, Midline2D; print('imports OK')"</automated>
  </verify>
  <done>
    - MidlineStage exists in core/midline/stage.py
    - Segment-then-extract backend fully implements U-Net segmentation + midline extraction
    - Direct pose backend raises NotImplementedError (stub)
    - run() reads context.detections and populates context.annotated_detections
    - No imports from engine/ in core/midline/
  </done>
</task>

<task type="auto">
  <name>Task 2: Interface tests for MidlineStage</name>
  <files>
    tests/unit/core/midline/__init__.py
    tests/unit/core/midline/test_midline_stage.py
  </files>
  <action>
Create interface tests:

1. **test_midline_stage_satisfies_protocol** — Instantiate MidlineStage (mock model loading) and assert isinstance(stage, Stage).

2. **test_midline_stage_populates_annotated_detections** — Create MidlineStage with mocked backend, feed a PipelineContext with synthetic detections data, assert context.annotated_detections is populated correctly.

3. **test_direct_pose_backend_raises** — Import the direct_pose backend and assert it raises NotImplementedError.

4. **test_backend_registry_unknown_raises** — Assert ValueError for unknown backend kind.

5. **test_import_boundary** — Inspect source of all modules in core/midline/ and assert no imports from aquapose.engine.

6. **test_missing_weights_raises** — Construct segment-then-extract backend with nonexistent weights path, assert clear error at construction.

Use mocks for UNetSegmentor and MidlineExtractor to avoid requiring real model weights in unit tests. Test the wiring and data flow, not the ML model.
  </action>
  <verify>
    <automated>hatch run test tests/unit/core/midline/test_midline_stage.py -x -v</automated>
  </verify>
  <done>
    - All tests pass
    - MidlineStage confirmed to satisfy Stage Protocol
    - Both backends tested (full implementation and stub)
    - Import boundary verified
  </done>
</task>

</tasks>

<verification>
1. `isinstance(MidlineStage(...), Stage)` returns True
2. `hatch run test tests/unit/core/midline/ -v` — all pass
3. `hatch run check` — no lint or type errors
4. grep for "engine" in src/aquapose/core/midline/ returns nothing
</verification>

<success_criteria>
- MidlineStage satisfies Stage Protocol via structural typing
- Segment-then-extract backend fully implements U-Net seg + midline extraction
- Direct pose stub proves the backend registry pattern
- run() populates context.annotated_detections from context.detections
- Interface tests pass
- No engine/ imports in core/midline/
</success_criteria>

<output>
After completion, create `.planning/phases/15-stage-migrations/15-02-SUMMARY.md`
</output>
