---
phase: 02.1-segmentation-troubleshooting
plan: 03
type: execute
wave: 3
depends_on:
  - 02.1-02
files_modified:
  - scripts/test_maskrcnn.py
autonomous: false
requirements:
  - SEG-4
must_haves:
  truths:
    - "Mask R-CNN trains on COCO JSON produced from Label Studio corrections"
    - "Mask R-CNN achieves >= 0.70 mean mask IoU on held-out frames"
    - "Visual overlay images show predicted masks on test frames for inspection"
  artifacts:
    - path: "scripts/test_maskrcnn.py"
      provides: "Mask R-CNN training and evaluation wrapper script"
      contains: "from aquapose.segmentation.training import train"
  key_links:
    - from: "scripts/test_maskrcnn.py"
      to: "src/aquapose/segmentation/training.py"
      via: "calls train() and evaluate()"
      pattern: "from aquapose.segmentation.training import train, evaluate"
    - from: "scripts/test_maskrcnn.py"
      to: "output/verify_pseudo_labels/coco_annotations.json"
      via: "COCO JSON from Label Studio round-trip"
      pattern: "coco_annotations.json"
---

<objective>
Complete the Label Studio round-trip to produce corrected training data, then train Mask R-CNN and evaluate on held-out frames.

Purpose: Mask R-CNN is the production segmentation model. This plan validates that the full pipeline (MOG2 detect -> SAM2 pseudo-label -> Label Studio correct -> Mask R-CNN train) produces a model that meets minimum quality for Phase 4.

Output: `scripts/test_maskrcnn.py` wrapping existing `training.train()` and `training.evaluate()`; trained model checkpoint; evaluation metrics
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02.1-segmentation-troubleshooting/02.1-RESEARCH.md
@.planning/phases/02.1-segmentation-troubleshooting/02.1-01-SUMMARY.md
@.planning/phases/02.1-segmentation-troubleshooting/02.1-02-SUMMARY.md

@src/aquapose/segmentation/training.py
@src/aquapose/segmentation/model.py
@src/aquapose/segmentation/dataset.py
@scripts/verify_pseudo_labels.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Mask R-CNN test script and prepare training pipeline</name>
  <files>scripts/test_maskrcnn.py</files>
  <action>
Create `scripts/test_maskrcnn.py` that wraps the existing `training.train()` and `training.evaluate()` functions.

**Script behavior:**
1. Accept CLI args:
   - `--coco-json` (required — path to COCO JSON from Label Studio import)
   - `--image-root` (required — path to source frame images)
   - `--output-dir` (default `output/test_maskrcnn`)
   - `--epochs` (default 40)
   - `--threshold` (default 0.70 — relaxed from Phase 2 target of 0.90)

2. Call `training.train()` with the COCO JSON and image root. Use `augment=True` to handle small training set size. Print training progress.

3. Call `training.evaluate()` on a held-out split (the training module should handle train/val splitting — check its API). Print evaluation metrics.

4. Save visual overlays: for each test image, overlay predicted masks on the original frame and save to `output-dir/visuals/`. Use colored contours per instance.

5. Print summary:
   - Number of training instances
   - Number of validation instances
   - Mean mask IoU on validation set
   - PASS/FAIL against threshold
   - Warning if training set < 50 instances (per RESEARCH.md pitfall 5)

6. Exit 0 if PASS, exit 1 if FAIL

**Important:** This script is a thin wrapper. The heavy lifting is already in `training.py`. Do NOT reimplement training logic. Read `training.py` to understand its API (train/evaluate function signatures, return values) and call it correctly.

**Before running:** The COCO JSON must exist from the Label Studio round-trip (user imports corrected annotations via `scripts/verify_pseudo_labels.py import`). This is handled by the checkpoint task below.
  </action>
  <verify>
- `scripts/test_maskrcnn.py` exists and `hatch run python scripts/test_maskrcnn.py --help` runs without error
- Script imports from `aquapose.segmentation.training` successfully
  </verify>
  <done>
Mask R-CNN test script created, imports verified. Ready for user to complete Label Studio round-trip.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: User completes Label Studio round-trip and runs Mask R-CNN training</name>
  <files>N/A — verification only</files>
  <action>
    This is a human verification checkpoint. Claude has automated the Mask R-CNN training/evaluation script. The user completes the Label Studio annotation round-trip and runs training.

    What was built:
    - Mask R-CNN test script (`scripts/test_maskrcnn.py`) wrapping existing `training.train()` and `training.evaluate()`
    - Produces visual overlays and numeric metrics

    Steps for user:

    **Step A: Label Studio round-trip** (if not already done)
    1. Open Label Studio and import `output/verify_pseudo_labels/tasks.json`
    2. Configure local file serving: set `LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT` to the parent of the `images/` directory (the `output/verify_pseudo_labels/` folder)
    3. Review and correct SAM2 pseudo-label masks (fix boundaries, add missed fish, remove false positives)
    4. Export corrected annotations as JSON from Label Studio
    5. Run: `hatch run python scripts/verify_pseudo_labels.py import --ls-export <export.json> --output-dir output/verify_pseudo_labels`
    6. Verify `output/verify_pseudo_labels/coco_annotations.json` exists

    **Step B: Train and evaluate**
    1. Run: `hatch run python scripts/test_maskrcnn.py --coco-json output/verify_pseudo_labels/coco_annotations.json --image-root output/verify_pseudo_labels/source_frames`
    2. Review training output and visual overlays in `output/test_maskrcnn/visuals/`
  </action>
  <verify>
    - Does training complete without error?
    - How many training instances? (if < 50, this is a known concern)
    - Does mean mask IoU on validation set >= 0.70?
    - Do the visual overlays in `output/test_maskrcnn/visuals/` look reasonable?
  </verify>
  <done>
    Mask R-CNN IoU >= 0.70 confirmed by user, or issues described for fix task. Type "approved" if passing, or describe failures.
  </done>
</task>

</tasks>

<verification>
- `scripts/test_maskrcnn.py` runs without error when provided valid COCO JSON
- Training completes and produces a model checkpoint
- Mean mask IoU on validation set printed and evaluated against 0.70 threshold
- Visual overlays saved for human inspection
</verification>

<success_criteria>
Mask R-CNN trained on Label Studio-corrected annotations achieves >= 0.70 mean mask IoU on held-out frames, validating the full segmentation pipeline from MOG2 detection through final mask prediction.
</success_criteria>

<output>
After completion, create `.planning/phases/02.1-segmentation-troubleshooting/02.1-03-SUMMARY.md`
</output>
