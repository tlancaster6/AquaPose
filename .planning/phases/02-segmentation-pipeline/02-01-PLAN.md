---
phase: 02-segmentation-pipeline
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - src/aquapose/segmentation/detector.py
  - src/aquapose/segmentation/__init__.py
  - tests/unit/segmentation/test_detector.py
autonomous: true

must_haves:
  truths:
    - "MOG2 detector produces bounding boxes for fish in video frames"
    - "Detector returns both bounding boxes AND rough foreground masks per detection"
    - "Small noise blobs are filtered out; only fish-sized detections survive"
    - "Shadow pixels (gray MOG2 output) are excluded from foreground"
  artifacts:
    - path: "src/aquapose/segmentation/detector.py"
      provides: "MOG2Detector class"
      exports: ["MOG2Detector"]
    - path: "tests/unit/segmentation/test_detector.py"
      provides: "Unit tests for detector"
      contains: "test_"
  key_links:
    - from: "src/aquapose/segmentation/__init__.py"
      to: "src/aquapose/segmentation/detector.py"
      via: "public API export"
      pattern: "MOG2Detector"
---

<objective>
Implement the MOG2 background-subtraction fish detector with morphological cleanup and bounding-box extraction.

Purpose: MOG2 detection is the entry point for the entire segmentation pipeline — it provides bounding boxes that feed SAM pseudo-labeling and later Mask R-CNN crops. Per user decision: global parameters across all 13 cameras, balanced recall/precision, no secondary fallback for stationary fish.

Output: `MOG2Detector` class in `detector.py`, unit tests.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-segmentation-pipeline/02-RESEARCH.md
</context>

<feature>
  <name>MOG2 Fish Detector</name>
  <files>src/aquapose/segmentation/detector.py, tests/unit/segmentation/test_detector.py</files>
  <behavior>
    MOG2Detector wraps cv2.BackgroundSubtractorMOG2 with morphological cleanup and connected-component filtering.

    **Constructor:** `MOG2Detector(history=500, var_threshold=12, detect_shadows=True, min_area=200, padding_fraction=0.15)`
    - Creates a cv2.BackgroundSubtractorMOG2 instance with given params
    - Sets shadow threshold to 200 (to exclude gray shadow pixels at value 127)
    - Stores morphological kernel: 5x5 ellipse (cv2.MORPH_ELLIPSE)
    - Stores min_area for blob filtering
    - padding_fraction controls how much to pad bboxes (fraction of bbox dimension)

    **Method:** `apply(frame: np.ndarray) -> None`
    - Feeds frame to MOG2 (.apply with default learning rate)
    - Frames MUST be fed in temporal order per camera (caller responsibility, documented)

    **Method:** `detect(frame: np.ndarray) -> list[Detection]`
    - Calls apply(frame) internally
    - Gets foreground mask from MOG2 (threshold at 255 to exclude shadows at 127)
    - Applies morphological close then open with the 5x5 ellipse kernel
    - Finds connected components (cv2.connectedComponentsWithStats)
    - Filters components by min_area
    - For each surviving component:
      - Extracts bounding box (x, y, w, h) from component stats
      - Pads bbox by padding_fraction (clipped to frame bounds)
      - Extracts component mask (binary mask of just this component within bbox region)
    - Returns list of Detection dataclass instances

    **Method:** `warm_up(frames: Sequence[np.ndarray]) -> None`
    - Feeds frames through apply() without returning detections
    - Used to build stable background model before detection begins

    **Dataclass:** `Detection`
    - bbox: tuple[int, int, int, int]  # (x, y, w, h)
    - mask: np.ndarray  # binary mask, same size as full frame, this component only
    - area: int  # pixel area of component
    - confidence: float  # 1.0 for MOG2 (placeholder for downstream compatibility)

    Cases:
    - Empty frame (no fish) -> empty list
    - Frame with one fish -> list with one Detection
    - Frame with noise blobs < min_area -> filtered out, not in results
    - Frame with multiple fish -> list with multiple Detections
    - Bbox near edge -> padding clipped to frame bounds
    - Shadow regions -> excluded from foreground mask (threshold at 255)
  </behavior>
  <implementation>
    Use cv2.createBackgroundSubtractorMOG2 with specified params. After creation, set
    BackgroundSubtractor shadow threshold to 200 via setShadowThreshold(200).

    For connected components, use cv2.connectedComponentsWithStats with connectivity=8.
    Stats columns: cv2.CC_STAT_LEFT, CC_STAT_TOP, CC_STAT_WIDTH, CC_STAT_HEIGHT, CC_STAT_AREA.
    Skip label 0 (background).

    Detection.mask should be a full-frame-sized binary uint8 array where only the pixels
    belonging to this specific connected component are set to 255. This format feeds
    directly into SAM as a mask prompt.

    Update __init__.py to export MOG2Detector and Detection.
  </implementation>
</feature>

<verification>
- `hatch run test tests/unit/segmentation/test_detector.py` — all tests pass
- `hatch run lint` — no lint errors
- `hatch run typecheck` — no type errors in detector.py
</verification>

<success_criteria>
MOG2Detector produces Detection objects with bounding boxes and per-component masks from video frames. Small blobs are filtered. Shadow pixels are excluded. Tests cover empty frames, single fish, multiple fish, edge padding, and warm-up.
</success_criteria>

<output>
After completion, create `.planning/phases/02-segmentation-pipeline/02-01-SUMMARY.md`
</output>
