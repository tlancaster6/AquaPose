---
phase: 23-refractive-lookup-tables
plan: 02
type: tdd
wave: 1
depends_on:
  - 23-01
files_modified:
  - src/aquapose/calibration/luts.py
  - src/aquapose/calibration/__init__.py
  - tests/unit/calibration/test_luts.py
autonomous: true
requirements:
  - LUT-02

must_haves:
  truths:
    - "InverseLUT discretizes the cylindrical tank volume into a voxel grid at configurable resolution and records per-voxel camera visibility masks and projected pixel coordinates"
    - "InverseLUT provides a camera overlap graph mapping each camera pair to the count of shared-visible voxels"
    - "InverseLUT provides ghost-point lookups: given a 3D point, return which cameras can see it and the expected pixel coordinates"
    - "InverseLUT is saved as a single shared .npz file and reloaded with hash-based cache invalidation"
    - "A coverage histogram is printed after inverse LUT generation showing percent of volume covered by 1+, 2+, 3+, 4+ cameras"
    - "Memory footprint of loaded forward + inverse LUTs is reported in the generation summary"
  artifacts:
    - path: "src/aquapose/calibration/luts.py"
      provides: "InverseLUT class, generate_inverse_lut(), camera_overlap_graph(), ghost_point_lookup(), save/load"
      contains: "InverseLUT"
    - path: "tests/unit/calibration/test_luts.py"
      provides: "Tests for InverseLUT voxel grid, overlap graph, ghost-point lookup, serialization"
      contains: "test_inverse_lut"
  key_links:
    - from: "src/aquapose/calibration/luts.py (InverseLUT)"
      to: "src/aquapose/calibration/projection.py"
      via: "RefractiveProjectionModel.project() used to project voxel centers into cameras"
      pattern: "project"
    - from: "src/aquapose/calibration/luts.py (InverseLUT)"
      to: "src/aquapose/calibration/luts.py (ForwardLUT)"
      via: "Shares LutConfig, compute_lut_hash, and save/load infrastructure from Plan 23-01"
      pattern: "LutConfig|compute_lut_hash"
---

<objective>
Build the inverse lookup table (voxel to pixel) system: an InverseLUT class that discretizes the cylindrical tank volume, records per-voxel camera visibility and projected pixel coordinates, and derives the camera overlap graph and ghost-point lookup table.

Purpose: Enables instant "which cameras see this 3D point?" queries for ghost-point penalty scoring (Phase 25 Step 1.3), camera overlap graph construction (Phase 25 Step 0), and fast reprojection during refinement (Phase 26). All without running the refraction model at query time.

Output: InverseLUT class added to calibration/luts.py, overlap graph and ghost-point query methods, unit tests.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/23-refractive-lookup-tables/23-CONTEXT.md
@.planning/phases/23-refractive-lookup-tables/23-01-SUMMARY.md

<interfaces>
<!-- Key types from Plan 23-01 that this plan builds upon -->

From src/aquapose/calibration/luts.py (created in 23-01):
```python
@dataclass
class ForwardLUT:
    camera_id: str
    grid_origins: np.ndarray    # (H, W, 3)
    grid_directions: np.ndarray # (H, W, 3)
    grid_step: int
    image_size: tuple[int, int]

    def cast_ray(self, pixels: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]: ...

def compute_lut_hash(calibration_path: str | Path, lut_config: LutConfig) -> str: ...
def save_forward_lut(lut: ForwardLUT, path: Path, config_hash: str) -> None: ...
def load_forward_lut(path: Path) -> tuple[ForwardLUT, str]: ...
```

From src/aquapose/calibration/projection.py:
```python
class RefractiveProjectionModel:
    def project(self, points: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:
        """Project 3D world points to 2D pixel coordinates.
        Returns: pixels (N, 2), valid (N,) boolean mask."""
```

From src/aquapose/engine/config.py:
```python
@dataclass(frozen=True)
class LutConfig:
    tank_diameter: float = 2.0
    tank_height: float = 1.0
    voxel_resolution_m: float = 0.02
    margin_fraction: float = 0.1
    forward_grid_step: int = 1
```

From src/aquapose/calibration/loader.py:
```python
@dataclass
class CalibrationData:
    cameras: dict[str, CameraData]
    water_z: float
    interface_normal: torch.Tensor
    n_air: float
    n_water: float

    @property
    def ring_cameras(self) -> list[str]: ...
    def camera_positions(self) -> dict[str, torch.Tensor]: ...
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement InverseLUT with voxel grid, overlap graph, and ghost-point lookup</name>
  <files>
    src/aquapose/calibration/luts.py
    src/aquapose/calibration/__init__.py
  </files>
  <action>
Add the InverseLUT class and supporting functions to `src/aquapose/calibration/luts.py`.

**Cylindrical voxel grid generation:**

`_build_cylindrical_voxel_grid(tank_center_xy, tank_diameter, tank_height, water_z, voxel_resolution, margin_fraction)` helper:
- Compute extents: radius = (tank_diameter / 2) * (1 + margin_fraction), height extends from water_z to water_z + tank_height * (1 + margin_fraction)
- Generate a regular 3D grid of voxel centers at `voxel_resolution` spacing
- Filter to only include voxels within the cylindrical volume: `sqrt((x - cx)^2 + (y - cy)^2) <= radius`
- Return: voxel_centers as ndarray shape (N_voxels, 3), plus grid metadata (bounds, resolution)

Tank center derivation (per CONTEXT.md decision): compute as the centroid of all ring camera XY positions from `calibration.camera_positions()`. Use `mean(cx), mean(cy)` of non-auxiliary camera positions.

**InverseLUT class:**
```python
@dataclass
class InverseLUT:
    """Inverse lookup table mapping 3D voxel centers to per-camera pixel projections.

    Discretizes the cylindrical tank volume and records which cameras can see
    each voxel and where it projects. Provides camera overlap graph and
    ghost-point lookups.

    Attributes:
        voxel_centers: 3D coordinates of all voxel centers, shape (N, 3), float32.
        visibility_mask: Boolean array, shape (N, C), True if camera c sees voxel n.
        projected_pixels: Pixel coordinates, shape (N, C, 2), float32. NaN where not visible.
        camera_ids: Ordered list of camera IDs (index into C dimension).
        voxel_resolution: Grid spacing in metres.
        grid_bounds: Dict with 'x_min', 'x_max', 'y_min', 'y_max', 'z_min', 'z_max'.
    """
```

**generate_inverse_lut(calibration, lut_config, undistortion_maps=None)** function:
- Derive tank center from camera position centroid (XY only, non-auxiliary cameras)
- Build cylindrical voxel grid
- For each ring camera:
  - Construct RefractiveProjectionModel (use K_new from undistortion_maps if available)
  - Project ALL voxel centers in a single batched call: `model.project(voxel_centers_tensor)`
  - Record visibility (valid mask AND within image bounds) and pixel coordinates
- Log per-camera progress: `"Projecting voxels into camera {cam_id}... done ({elapsed:.1f}s)"`
- Print camera overlap coverage histogram after completion:
  ```
  Camera coverage histogram:
    1+ cameras: 98.2% of voxels
    2+ cameras: 87.5% of voxels
    3+ cameras: 72.1% of voxels
    ...
  ```
- Report total memory footprint: `"LUT memory: forward {fwd_mb:.1f} MB + inverse {inv_mb:.1f} MB = {total:.1f} MB total"`
- Return InverseLUT instance

**camera_overlap_graph(inverse_lut, min_shared_voxels=100)** function:
- For each camera pair (i, j), count voxels where both have visibility=True
- Return `dict[tuple[str, str], int]` mapping camera pair to shared voxel count
- Only include pairs exceeding `min_shared_voxels`
- Camera pairs are sorted tuples for consistency: `(min(a,b), max(a,b))`

**ghost_point_lookup(inverse_lut, points_3d)** method or function:
- Input: points_3d tensor shape (N, 3)
- For each point, snap to nearest voxel (by Euclidean distance to voxel_centers; use a KD-tree built at InverseLUT construction time for efficiency, or simple vectorized distance if voxel count is manageable)
- Actually, for the voxel grid: convert point to grid index directly via `(point - grid_min) / resolution`, floor to int, clamp to bounds. This is O(1) per point, no KD-tree needed. But voxels are cylindrical, so use the flat array: store a mapping from (ix, iy, iz) grid indices to voxel array index.
- Implementation approach: Store an auxiliary `_grid_to_voxel_idx` dict or 3D array mapping integer grid coordinates to voxel indices. Points outside the cylinder return empty results.
- Return for each point: list of `(camera_id, pixel_u, pixel_v)` for cameras that can see the nearest voxel

**Validation:**

`validate_inverse_lut(inverse_lut, calibration, n_samples=50, seed=42)` function:
- Sample `n_samples` random voxel indices
- For each, take the voxel center and project through the on-the-fly RefractiveProjectionModel
- Compare with stored projected_pixels
- Report max/mean pixel error
- Raise ValueError if max pixel error exceeds 1.0 px (should be near-zero since projection is exact, not interpolated)

**Serialization:**

`save_inverse_lut(lut, path, config_hash)`:
- Save to a single .npz: voxel_centers, visibility_mask, projected_pixels, camera_ids, voxel_resolution, grid_bounds, config_hash
- Also save the `_grid_to_voxel_idx` mapping (as coordinate arrays, not a dict)

`load_inverse_lut(path)`:
- Load and reconstruct InverseLUT including the grid index mapping
- Return (InverseLUT, config_hash)

`save_inverse_luts(lut, calibration_path, lut_config)`:
- Directory: `Path(calibration_path).parent / "luts"`
- File: `inverse.npz`

`load_inverse_luts(calibration_path, lut_config)`:
- Check hash, return InverseLUT or None

**Update `src/aquapose/calibration/__init__.py`:**

Add imports for: `InverseLUT`, `generate_inverse_lut`, `camera_overlap_graph`, `ghost_point_lookup`, `validate_inverse_lut`, `save_inverse_lut`, `load_inverse_lut`. Add to `__all__`.
  </action>
  <verify>
    <automated>cd C:/Users/tucke/PycharmProjects/AquaPose && python -c "
from aquapose.calibration.luts import InverseLUT, generate_inverse_lut, camera_overlap_graph, ghost_point_lookup
from aquapose.calibration import InverseLUT as InverseLUT2
print('Imports OK')
"</automated>
  </verify>
  <done>InverseLUT class exists with voxel_centers, visibility_mask, projected_pixels. generate_inverse_lut() builds the voxel grid for a cylindrical tank with camera projection. camera_overlap_graph() returns shared-voxel counts per camera pair. ghost_point_lookup() returns per-camera visibility and pixel coords for arbitrary 3D points. Coverage histogram and memory footprint are printed during generation. Serialization saves/loads to inverse.npz with hash-based caching.</done>
</task>

<task type="auto">
  <name>Task 2: Write unit tests for InverseLUT generation, overlap graph, ghost-point lookup, and serialization</name>
  <files>
    tests/unit/calibration/test_luts.py
  </files>
  <action>
Add tests to the existing `tests/unit/calibration/test_luts.py` (created in Plan 23-01). Use synthetic multi-camera setups to test the inverse LUT.

**Test fixtures:**

Create a `make_test_rig()` helper that builds a CalibrationData with 3-4 synthetic cameras arranged in a ring around a small cylindrical volume:
- Camera 1: above tank at (0.3, 0, -0.3), looking toward center, 640x480 image
- Camera 2: above tank at (-0.3, 0, -0.3), looking toward center
- Camera 3: above tank at (0, 0.3, -0.3), looking toward center
- Use simple rotation matrices that point each camera roughly toward the tank center
- water_z = 0.0, n_air = 1.0, n_water = 1.333, normal = [0, 0, -1]
- All cameras non-auxiliary (is_auxiliary=False)
- Small tank: diameter=0.5m, height=0.3m

Use a coarser voxel resolution (e.g., 0.05m) for fast test execution.

**Tests:**

1. `test_cylindrical_voxel_grid_shape()`:
   - Build grid with known diameter=0.5, height=0.3, resolution=0.05, margin=0.1
   - Assert all voxels are within the expanded cylinder (radius * 1.1, height * 1.1)
   - Assert z-values are between water_z and water_z + height * 1.1
   - Assert voxel count is reasonable (roughly pi * r^2 * h / res^3)

2. `test_inverse_lut_visibility_mask_shape()`:
   - Generate InverseLUT from the 3-camera rig
   - Assert visibility_mask shape is (N_voxels, 3)
   - Assert projected_pixels shape is (N_voxels, 3, 2)
   - Assert at least some voxels are visible to all 3 cameras
   - Assert NaN pixels where visibility is False

3. `test_inverse_lut_projected_pixels_match_model()`:
   - Generate InverseLUT
   - Pick 20 random voxels where visibility is True for a given camera
   - Project those voxel centers through RefractiveProjectionModel.project()
   - Assert pixel coordinates match within 0.01 px (should be exact)

4. `test_camera_overlap_graph()`:
   - Generate InverseLUT
   - Call camera_overlap_graph() with min_shared_voxels=1
   - Assert all 3 camera pairs are present (3-camera rig has C(3,2)=3 pairs)
   - Assert shared voxel counts are > 0 for all pairs (since cameras overlap)

5. `test_ghost_point_lookup_returns_visible_cameras()`:
   - Generate InverseLUT
   - Pick a voxel center that is visible to all 3 cameras
   - Call ghost_point_lookup() with that point
   - Assert all 3 cameras returned with valid pixel coordinates
   - Pick a point outside the tank volume
   - Assert empty or no results returned

6. `test_inverse_lut_serialization_roundtrip(tmp_path)`:
   - Generate InverseLUT
   - Save and reload via save_inverse_lut / load_inverse_lut
   - Assert voxel_centers, visibility_mask, projected_pixels match exactly
   - Assert camera_ids match

7. `test_validate_inverse_lut_passes()`:
   - Generate InverseLUT from the rig
   - Call validate_inverse_lut() — should not raise
   - Assert max pixel error < 0.01 px

8. `test_coverage_histogram_output(capsys)`:
   - Generate InverseLUT (which prints the histogram)
   - Capture stdout and assert it contains "Camera coverage histogram" and percentage lines

All tests use deterministic seeds and run on CPU. The 3-camera rig with coarse voxels ensures tests complete in under 5 seconds total.
  </action>
  <verify>
    <automated>cd C:/Users/tucke/PycharmProjects/AquaPose && hatch run python -m pytest tests/unit/calibration/test_luts.py -x -v 2>&1 | tail -40</automated>
  </verify>
  <done>All inverse LUT tests pass. Voxel grid is cylindrical. Visibility mask and projected pixels are correct. Camera overlap graph returns expected pairs. Ghost-point lookup returns correct cameras and pixels. Serialization round-trips without data loss. Coverage histogram is printed during generation.</done>
</task>

</tasks>

<verification>
1. `python -c "from aquapose.calibration import InverseLUT, generate_inverse_lut, camera_overlap_graph, ghost_point_lookup"` succeeds
2. `hatch run python -m pytest tests/unit/calibration/test_luts.py -x -v` — all tests pass (both forward and inverse)
3. `hatch run check` — lint and typecheck pass
4. InverseLUT.projected_pixels matches RefractiveProjectionModel.project() within 0.01 px for sampled voxels
5. camera_overlap_graph returns non-empty overlap for cameras with shared field of view
6. ghost_point_lookup returns correct camera visibility for points inside the tank volume
</verification>

<success_criteria>
- InverseLUT discretizes the cylindrical tank volume and records per-voxel camera visibility and pixel projections
- Camera overlap graph correctly identifies adjacent camera pairs from shared voxel visibility
- Ghost-point lookup returns expected cameras and pixel coordinates for arbitrary 3D points
- Inverse LUT serializes to a single .npz and reloads with hash-based cache invalidation
- Coverage histogram and memory footprint are printed during generation
- All unit tests pass for both forward (23-01) and inverse (23-02) LUTs
</success_criteria>

<output>
After completion, create `.planning/phases/23-refractive-lookup-tables/23-02-SUMMARY.md`
</output>
