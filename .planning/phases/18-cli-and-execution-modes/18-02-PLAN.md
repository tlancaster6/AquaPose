---
phase: 18-cli-and-execution-modes
plan: 02
type: execute
wave: 2
depends_on: [18-01]
files_modified:
  - src/aquapose/cli.py
  - tests/unit/engine/test_cli.py
autonomous: true
requirements: [CLI-03, CLI-05]

must_haves:
  truths:
    - "`aquapose run --mode diagnostic` activates ALL 5 observers (timing, HDF5, overlay2d, animation3d, diagnostic) plus console"
    - "`aquapose run --mode benchmark` activates TimingObserver ONLY (plus console) — no HDF5, no visualization"
    - "Diagnostic mode produces extra artifacts without any code change to stages or core observers"
    - "Benchmark mode reports per-stage and total time with minimal overhead"
  artifacts:
    - path: "src/aquapose/cli.py"
      provides: "Mode-based observer assembly for diagnostic and benchmark modes"
      contains: "diagnostic"
    - path: "tests/unit/engine/test_cli.py"
      provides: "Tests for diagnostic and benchmark mode observer assembly"
  key_links:
    - from: "src/aquapose/cli.py"
      to: "aquapose.engine.DiagnosticObserver"
      via: "diagnostic mode instantiates DiagnosticObserver"
      pattern: "DiagnosticObserver"
    - from: "src/aquapose/cli.py"
      to: "aquapose.engine.Overlay2DObserver"
      via: "diagnostic mode instantiates Overlay2DObserver"
      pattern: "Overlay2DObserver"
    - from: "src/aquapose/cli.py"
      to: "aquapose.engine.Animation3DObserver"
      via: "diagnostic mode instantiates Animation3DObserver"
      pattern: "Animation3DObserver"
---

<objective>
Add diagnostic and benchmark execution modes to the CLI entrypoint.

Purpose: Diagnostic mode provides full introspection by attaching all 5 observers, enabling developers to see every intermediate result. Benchmark mode strips all non-timing observers for pure performance measurement.

Output: `--mode diagnostic` and `--mode benchmark` flags that assemble the correct observer sets with no changes to stages or observers.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/18-cli-and-execution-modes/18-CONTEXT.md
@.planning/phases/18-cli-and-execution-modes/18-01-SUMMARY.md

<interfaces>
<!-- Observer constructors the executor needs -->

From src/aquapose/engine/timing.py:
```python
class TimingObserver:
    def __init__(self, output_path: str | Path | None = None) -> None: ...
```

From src/aquapose/engine/hdf5_observer.py:
```python
class HDF5ExportObserver:
    def __init__(self, output_dir: str | Path) -> None: ...
```

From src/aquapose/engine/overlay_observer.py:
```python
class Overlay2DObserver:
    def __init__(self, output_dir: str | Path, video_dir: str | Path, calibration_path: str | Path) -> None: ...
```

From src/aquapose/engine/animation_observer.py:
```python
class Animation3DObserver:
    def __init__(self, output_dir: str | Path) -> None: ...
```

From src/aquapose/engine/diagnostic_observer.py:
```python
class DiagnosticObserver:
    def __init__(self) -> None: ...
```

From src/aquapose/engine/console_observer.py (created in 18-01):
```python
class ConsoleObserver:
    def __init__(self, verbose: bool = False, total_stages: int = 5) -> None: ...
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement diagnostic and benchmark mode observer assembly and tests</name>
  <files>
    src/aquapose/cli.py
    tests/unit/engine/test_cli.py
  </files>
  <action>
**1. Update `src/aquapose/cli.py` observer assembly logic:**

In the `run()` command function, extend the mode-based observer assembly:

- **Diagnostic mode** (`--mode diagnostic`): Assemble ALL 5 observers plus ConsoleObserver:
  - `ConsoleObserver(verbose=verbose, total_stages=len(stages))`
  - `TimingObserver(output_path=Path(config.output_dir) / "timing.txt")`
  - `HDF5ExportObserver(output_dir=config.output_dir)`
  - `Overlay2DObserver(output_dir=config.output_dir, video_dir=config.video_dir, calibration_path=config.calibration_path)`
  - `Animation3DObserver(output_dir=config.output_dir)`
  - `DiagnosticObserver()`

- **Benchmark mode** (`--mode benchmark`): Minimal observers for timing only:
  - `ConsoleObserver(verbose=verbose, total_stages=len(stages))`
  - `TimingObserver(output_path=Path(config.output_dir) / "timing.txt")`
  - No HDF5, no visualization, no diagnostic capture.

Structure this as a helper function `_build_observers(config: PipelineConfig, mode: str, verbose: bool, total_stages: int, extra_observers: list[str]) -> list[Observer]` to keep the `run()` command clean. This function:
  1. Starts with ConsoleObserver always.
  2. Switches on mode to add mode-specific observers.
  3. Processes `extra_observers` from `--add-observer` flags additively.
  4. Returns the final list.

Import Overlay2DObserver, Animation3DObserver, and DiagnosticObserver from aquapose.engine.

**2. Update `tests/unit/engine/test_cli.py`:**

Add tests for the new modes:

- `test_diagnostic_mode_assembles_all_observers`: Mock pipeline and verify that `--mode diagnostic` creates an observer list containing instances of all 5 observer types (TimingObserver, HDF5ExportObserver, Overlay2DObserver, Animation3DObserver, DiagnosticObserver) plus ConsoleObserver. Mock at the `PosePipeline` constructor level and inspect the `observers` argument.
- `test_benchmark_mode_assembles_timing_only`: Mock pipeline and verify that `--mode benchmark` creates an observer list with only TimingObserver + ConsoleObserver. Explicitly assert Overlay2DObserver, Animation3DObserver, HDF5ExportObserver, and DiagnosticObserver are NOT in the list.
- `test_add_observer_augments_mode`: Verify that `--mode benchmark --add-observer hdf5` adds HDF5ExportObserver on top of benchmark's default set.

All tests use `click.testing.CliRunner` and mock `load_config`, `build_stages`, and `PosePipeline` to avoid real pipeline execution.
  </action>
  <verify>
    <automated>cd C:/Users/tucke/PycharmProjects/AquaPose && python -m pytest tests/unit/engine/test_cli.py -x -v -k "diagnostic or benchmark or add_observer"</automated>
  </verify>
  <done>
    - `--mode diagnostic` creates observer list with all 5 observer types plus ConsoleObserver
    - `--mode benchmark` creates observer list with TimingObserver + ConsoleObserver only
    - `--add-observer` flag adds observers additively on top of mode defaults
    - Observer assembly is a clean helper function, not inline logic
    - All existing and new CLI tests pass
  </done>
</task>

</tasks>

<verification>
1. `python -m pytest tests/unit/engine/test_cli.py -x -v` — all tests pass including diagnostic/benchmark mode tests
2. `grep -c "DiagnosticObserver\|Animation3DObserver\|Overlay2DObserver" src/aquapose/cli.py` shows these observers are referenced
3. `grep -c "def detect\|def triangulate\|def reconstruct\|def segment" src/aquapose/cli.py` returns 0 — no computation logic leaked into CLI
</verification>

<success_criteria>
- `--mode diagnostic` attaches all 5 observers, providing full introspection
- `--mode benchmark` attaches timing observer only, measuring pure computation time
- `--add-observer` flag works additively on any mode
- No pipeline computation logic exists in the CLI module
</success_criteria>

<output>
After completion, create `.planning/phases/18-cli-and-execution-modes/18-02-SUMMARY.md`
</output>
