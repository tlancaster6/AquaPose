---
phase: 04-per-fish-reconstruction
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/aquapose/optimization/renderer.py
  - src/aquapose/optimization/loss.py
  - src/aquapose/optimization/__init__.py
  - tests/unit/optimization/__init__.py
  - tests/unit/optimization/test_renderer.py
  - tests/unit/optimization/test_loss.py
autonomous: true
requirements: [RECON-01, RECON-02]
must_haves:
  truths:
    - "Fish mesh renders to a non-empty differentiable silhouette alpha map for each camera view via refractive projection"
    - "Gradients flow from the rendered silhouette loss back through all 5 FishState parameters (p, psi, theta, kappa, s)"
    - "Multi-objective loss combines camera-weighted soft IoU + gravity prior + morphological constraints + temporal hook"
    - "Angular diversity weighting down-weights clustered ring cameras based on extrinsic view directions"
  artifacts:
    - path: "src/aquapose/optimization/renderer.py"
      provides: "RefractiveCamera wrapper and RefractiveSilhouetteRenderer"
      exports: ["RefractiveCamera", "RefractiveSilhouetteRenderer"]
    - path: "src/aquapose/optimization/loss.py"
      provides: "Soft IoU loss, multi-objective loss, angular diversity weighting"
      exports: ["soft_iou_loss", "multi_objective_loss", "compute_angular_diversity_weights"]
    - path: "tests/unit/optimization/test_renderer.py"
      provides: "Renderer gradient flow and silhouette shape tests"
    - path: "tests/unit/optimization/test_loss.py"
      provides: "Loss function correctness and gradient flow tests"
  key_links:
    - from: "src/aquapose/optimization/renderer.py"
      to: "aquapose.calibration.projection.RefractiveProjectionModel"
      via: "RefractiveCamera.transform_points calls model.project()"
      pattern: "model\\.project\\("
    - from: "src/aquapose/optimization/renderer.py"
      to: "pytorch3d.renderer.MeshRasterizer"
      via: "Rasterizer uses RefractiveCamera for vertex projection"
      pattern: "MeshRasterizer"
    - from: "src/aquapose/optimization/loss.py"
      to: "src/aquapose/mesh/state.py"
      via: "multi_objective_loss reads FishState fields for gravity/morph terms"
      pattern: "state\\.kappa|state\\.s|state\\.theta"
---

<objective>
Build the differentiable silhouette renderer and multi-objective loss for analysis-by-synthesis pose optimization.

Purpose: Provide the forward-pass rendering pipeline (mesh -> per-camera alpha maps via refractive projection) and the loss computation (weighted IoU + priors) that the optimizer loop in Plan 02 will call each iteration. This is the computational core of the reconstruction system.

Output: `renderer.py` (RefractiveCamera + RefractiveSilhouetteRenderer), `loss.py` (soft_iou_loss, multi_objective_loss, compute_angular_diversity_weights), and comprehensive unit tests verifying gradient flow and correctness.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-per-fish-reconstruction/04-RESEARCH.md
@.planning/phases/03-fish-mesh-model-and-3d-initialization/03-01-SUMMARY.md

Key upstream APIs:
- `RefractiveProjectionModel.project(points_3d) -> (pixels, valid)` — differentiable 3D→2D refractive projection (10 fixed Newton-Raphson iters)
- `build_fish_mesh(states: list[FishState]) -> Meshes` — watertight PyTorch3D Meshes with gradient flow
- `FishState(p, psi, theta, kappa, s)` — 5-parameter pose state vector
- `CropRegion(x1, y1, x2, y2, frame_h, frame_w)` — from segmentation.crop
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix pytorch3d import and build RefractiveCamera + RefractiveSilhouetteRenderer</name>
  <files>
    src/aquapose/optimization/renderer.py
    src/aquapose/optimization/__init__.py
    tests/unit/optimization/__init__.py
    tests/unit/optimization/test_renderer.py
  </files>
  <action>
  **Step 0: Fix pytorch3d import blocker.**
  The installed `pytorch3d-0.7.9+pt2.9.1cu128` fails to import on `torch 2.10.0+cu130` (ABI mismatch). Downgrade torch:
  ```bash
  pip install torch==2.9.1+cu128 torchvision==0.20.1+cu128 --index-url https://download.pytorch.org/whl/cu128
  python -c "from pytorch3d.renderer import SoftSilhouetteShader; print('OK')"
  ```
  If the downgrade causes other issues, try CPU-only pytorch3d build as fallback:
  ```bash
  pip uninstall pytorch3d -y
  FORCE_CUDA=0 pip install "git+https://github.com/facebookresearch/pytorch3d.git"
  ```
  Verify existing tests still pass after the torch change: `hatch run test`

  **Step 1: Create `src/aquapose/optimization/renderer.py`.**

  Implement `RefractiveCamera` — a thin PyTorch3D-compatible camera wrapper:
  - `__init__(self, model: RefractiveProjectionModel, image_size: tuple[int, int])` — stores model and image dims
  - `transform_points(self, world_pts: Tensor) -> Tensor` — calls `model.project(world_pts)` to get pixel coords `(N, 2)`, converts to PyTorch3D NDC `(N, 3)`:
    - `ndc_x = (u / W) * 2.0 - 1.0` (left-to-right)
    - `ndc_y = -((v / H) * 2.0 - 1.0)` (flip Y for PyTorch3D +Y up convention)
    - `z = world_pts[:, 2]` (kept for depth sorting)
  - Handle `valid` mask from `project()` — set invalid points to 0 NDC coords
  - Must propagate gradients from NDC back through `project()` to world-space vertices

  Implement `RefractiveSilhouetteRenderer`:
  - `__init__(self, image_size, sigma=1e-4, gamma=1e-4, faces_per_pixel=100)` — create `RasterizationSettings` with `blur_radius = np.log(1/1e-4 - 1) * sigma`, store `BlendParams(sigma, gamma)`
  - `render(self, meshes: Meshes, cameras: list[RefractiveProjectionModel], camera_ids: list[str]) -> dict[str, Tensor]` — for each camera:
    1. Wrap in `RefractiveCamera(model, self.image_size)`
    2. Create `MeshRasterizer(cameras=cam, raster_settings=self.raster_settings)`
    3. Create `SoftSilhouetteShader(blend_params=self.blend_params)`
    4. Create `MeshRenderer(rasterizer, shader)`
    5. Render: `images = renderer(meshes)` → alpha = `images[..., 3]` (shape `(1, H, W)`)
    6. Return `{cam_id: alpha.squeeze(0)}` for each camera
  - NOTE: The RefractiveCamera must satisfy PyTorch3D's camera interface. If `MeshRasterizer` performs type checks and rejects the custom class, use the alternative approach: pre-project mesh vertices via `model.project()`, construct NDC-space mesh, and render with a trivial orthographic camera. Document whichever approach works.

  **Step 2: Create `tests/unit/optimization/test_renderer.py`.**
  - `test_renderer_produces_nonempty_silhouette`: Create a synthetic FishState at depth ~1.5m, a mock RefractiveProjectionModel (or use a simple pinhole approximation), render, assert alpha map has nonzero pixels
  - `test_renderer_gradient_flow_all_params`: Create FishState with `requires_grad=True` on all 5 params, render, compute `alpha.sum()`, call `.backward()`, assert all 5 grads are not None and finite
  - `test_renderer_alpha_range`: Assert alpha values are in [0, 1]
  - `test_renderer_multiple_cameras`: Render with 2+ cameras, assert dict has correct keys and shapes

  Create `tests/unit/optimization/__init__.py` (empty).

  **Step 3: Update `src/aquapose/optimization/__init__.py`** with public exports:
  `RefractiveCamera`, `RefractiveSilhouetteRenderer` in `__all__`.
  </action>
  <verify>
  ```bash
  python -c "from pytorch3d.renderer import SoftSilhouetteShader; print('OK')"
  hatch run test tests/unit/optimization/test_renderer.py -v
  hatch run test  # all existing tests still pass
  ```
  </verify>
  <done>
  - pytorch3d imports successfully
  - RefractiveCamera wraps RefractiveProjectionModel for PyTorch3D rasterizer
  - RefractiveSilhouetteRenderer produces differentiable alpha maps per camera
  - Gradients flow from rendered silhouette through all 5 FishState parameters
  - All existing tests still pass after torch version change
  </done>
</task>

<task type="auto">
  <name>Task 2: Build multi-objective loss with angular diversity weighting</name>
  <files>
    src/aquapose/optimization/loss.py
    src/aquapose/optimization/__init__.py
    tests/unit/optimization/test_loss.py
  </files>
  <action>
  **Step 1: Create `src/aquapose/optimization/loss.py`.**

  Implement `soft_iou_loss(pred_alpha, target_mask, crop_region=None, eps=1e-6) -> Tensor`:
  - `pred_alpha`: (H, W) float [0,1], `target_mask`: (H, W) binary float
  - If `crop_region` is a tuple `(y1, x1, y2, x2)`, slice both tensors to that region before computing
  - Formula: `intersection = (pred * target).sum(); union = (pred + target - pred * target).sum(); return 1.0 - intersection / (union + eps)`
  - Differentiable with respect to `pred_alpha`

  Implement `compute_angular_diversity_weights(models, camera_ids, temperature=0.5) -> dict[str, float]`:
  - Extract view direction from each camera's R matrix: `view_dir = R.T @ [0, 0, -1]` (world-space), normalize
  - For each camera i, compute minimum angle to all other cameras j: `min_angle_i = min(arccos(dot(v_i, v_j)))` for j != i
  - Weight = `(min_angle / max_min_angle) ** temperature`
  - Return dict mapping camera_id to weight in (0, 1]
  - Use numpy for the static computation (weights computed once, not per-iteration)

  Implement `multi_objective_loss(state, pred_alphas, target_masks, crop_regions, camera_weights, loss_weights, temporal_state=None, temporal_weight=0.1, kappa_max=10.0, s_min=0.05, s_max=0.30) -> dict[str, Tensor]`:
  - Computes weighted sum of per-camera `soft_iou_loss`, normalized by sum of camera weights
  - Gravity prior: `loss_weights.get("gravity", 0.05) * state.theta ** 2` — penalizes pitch deviation from horizontal (proxy for roll per RESEARCH.md recommendation; true roll requires FishState extension)
  - Morphological constraints: `loss_weights.get("morph", 0.2) * (relu(|kappa| - kappa_max)^2 + relu(s_min - s)^2 + relu(s - s_max)^2)` — kappa bounds stricter than scale bounds per user decision
  - Temporal smoothness: if `temporal_state` is not None, compute `(state.p - temporal_state.p).norm()^2 + (state.psi - temporal_state.psi)^2` scaled by `temporal_weight`. In Phase 4, `temporal_state=None` always (hook present but inactive until Phase 5).
  - Return dict: `{"total": ..., "iou": ..., "gravity": ..., "morph": ..., "temporal": ...}`

  **Step 2: Create `tests/unit/optimization/test_loss.py`.**
  - `test_soft_iou_perfect_overlap`: pred==target → loss near 0
  - `test_soft_iou_no_overlap`: disjoint pred and target → loss near 1
  - `test_soft_iou_partial_overlap`: known overlap → expected IoU value
  - `test_soft_iou_crop_region`: verify crop slicing works correctly
  - `test_soft_iou_gradient_flows`: backward through pred_alpha succeeds
  - `test_angular_diversity_weights_clustered`: cameras at similar angles get lower weight
  - `test_angular_diversity_weights_diverse`: well-separated cameras get higher weight
  - `test_multi_objective_loss_keys`: returns all 5 expected keys
  - `test_multi_objective_loss_gravity_increases_with_theta`: higher theta → higher gravity loss
  - `test_multi_objective_loss_morph_zero_in_bounds`: kappa and s within bounds → morph loss is 0
  - `test_multi_objective_loss_morph_nonzero_out_of_bounds`: kappa or s out of bounds → positive morph loss
  - `test_multi_objective_loss_temporal_inactive`: temporal_state=None → temporal loss is 0

  **Step 3: Update `src/aquapose/optimization/__init__.py`** adding `soft_iou_loss`, `multi_objective_loss`, `compute_angular_diversity_weights` to `__all__`.
  </action>
  <verify>
  ```bash
  hatch run test tests/unit/optimization/test_loss.py -v
  hatch run test  # all tests pass
  ```
  </verify>
  <done>
  - soft_iou_loss computes differentiable crop-space IoU between predicted and observed silhouettes
  - compute_angular_diversity_weights produces per-camera weights from extrinsic view directions
  - multi_objective_loss combines weighted IoU + gravity prior + morphological constraints + temporal hook
  - Temporal smoothness term is architecturally present but inactive (temporal_state=None in Phase 4)
  - All loss tests pass including gradient flow verification
  </done>
</task>

</tasks>

<verification>
```bash
# All Phase 4 Plan 01 tests pass
hatch run test tests/unit/optimization/ -v

# pytorch3d imports work
python -c "from pytorch3d.renderer import SoftSilhouetteShader, MeshRasterizer; print('OK')"

# All existing tests still pass (no regressions from torch downgrade)
hatch run test

# Gradient flow end-to-end: FishState -> mesh -> render -> loss -> backward
# (covered by test_renderer_gradient_flow_all_params)
```
</verification>

<success_criteria>
- pytorch3d renderer imports successfully on the environment
- Differentiable silhouette rendering produces non-empty alpha maps from fish mesh + refractive cameras
- Gradients flow from loss backward through renderer to all 5 FishState parameters
- Multi-objective loss correctly weights per-camera IoU by angular diversity
- Gravity and morphological priors activate for out-of-range state values
- Temporal smoothness hook is present but returns 0 when no tracking data provided
- All existing project tests pass without regression
</success_criteria>

<output>
After completion, create `.planning/phases/04-per-fish-reconstruction/04-01-SUMMARY.md`
</output>
