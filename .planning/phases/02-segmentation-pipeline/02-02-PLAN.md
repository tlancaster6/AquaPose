---
phase: 02-segmentation-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - src/aquapose/segmentation/pseudo_labeler.py
  - src/aquapose/segmentation/label_studio.py
  - src/aquapose/segmentation/__init__.py
  - tests/unit/segmentation/test_pseudo_labeler.py
  - tests/unit/segmentation/test_label_studio.py
autonomous: false

must_haves:
  truths:
    - "SAM2 generates segmentation masks from bounding box + rough mask prompts"
    - "Pseudo-labels can be exported to Label Studio brush format for human review"
    - "Corrected annotations can be imported back as COCO JSON with RLE masks"
    - "Negative frames (no fish) are included in annotation exports"
  artifacts:
    - path: "src/aquapose/segmentation/pseudo_labeler.py"
      provides: "SAMPseudoLabeler class"
      exports: ["SAMPseudoLabeler"]
    - path: "src/aquapose/segmentation/label_studio.py"
      provides: "Label Studio export/import utilities"
      exports: ["export_to_label_studio", "import_from_label_studio"]
    - path: "tests/unit/segmentation/test_pseudo_labeler.py"
      provides: "Pseudo-labeler unit tests"
      contains: "test_"
    - path: "tests/unit/segmentation/test_label_studio.py"
      provides: "Label Studio IO unit tests"
      contains: "test_"
  key_links:
    - from: "src/aquapose/segmentation/pseudo_labeler.py"
      to: "src/aquapose/segmentation/detector.py"
      via: "consumes Detection dataclass"
      pattern: "Detection"
    - from: "src/aquapose/segmentation/label_studio.py"
      to: "src/aquapose/segmentation/pseudo_labeler.py"
      via: "converts pseudo-label masks to LS format"
      pattern: "mask2rle"
---

<objective>
Implement SAM2 pseudo-label generation from MOG2 detections and Label Studio annotation workflow (export pseudo-labels, import corrected masks).

Purpose: SAM2 refines rough MOG2 masks into high-quality pseudo-labels. These feed into Label Studio for human review/correction, producing the training dataset for Mask R-CNN. Per user decision: all pseudo-labels get human review (no confidence-based skip), BrushLabels format, temporal sampling for frame selection.

Output: `SAMPseudoLabeler` class, Label Studio export/import utilities, unit tests.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-segmentation-pipeline/02-RESEARCH.md
@.planning/phases/02-segmentation-pipeline/02-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: SAM2 pseudo-labeler and Label Studio IO</name>
  <files>
    src/aquapose/segmentation/pseudo_labeler.py
    src/aquapose/segmentation/label_studio.py
    src/aquapose/segmentation/__init__.py
    tests/unit/segmentation/test_pseudo_labeler.py
    tests/unit/segmentation/test_label_studio.py
  </files>
  <action>
    **pseudo_labeler.py — SAMPseudoLabeler class:**

    Constructor: `SAMPseudoLabeler(model_variant: str = "facebook/sam2.1-hiera-large", device: str | None = None)`
    - Lazy-loads SAM2ImagePredictor on first use (avoid GPU memory on import)
    - Stores device (auto-detect cuda/cpu if None)

    Method: `predict(image: np.ndarray, detections: list[Detection]) -> list[np.ndarray]`
    - Sets image on predictor via `set_image(image)` (FULL image, NOT cropped — per research anti-pattern)
    - For each Detection:
      - Convert bbox (x, y, w, h) to SAM2 format [x1, y1, x2, y2] as np.array
      - Also pass Detection.mask as mask prompt (logits input) — resize to 256x256 if needed by SAM
      - Call `predict(box=box_prompt, mask_input=mask_logit, multimask_output=False)`
      - Extract binary mask from output (threshold at 0.5)
    - Returns list of binary masks (uint8, full frame size, one per detection)

    NOTE: SAM2 mask_input requires logits (not binary). Convert Detection.mask (binary 0/255) to
    logits: where mask>0 set to +4.0, else -4.0. Resize to 256x256 for SAM2's expected input size.
    If mask_input proves problematic in practice, fall back to box-only prompts (document in code).

    **label_studio.py — Export/Import utilities:**

    Function: `export_to_label_studio(frames: list[FrameAnnotation], output_dir: Path, project_name: str = "aquapose") -> Path`
    - FrameAnnotation dataclass: frame_id (str), image_path (Path), masks (list[np.ndarray]), camera_id (str)
    - Writes images to output_dir/images/ (symlinks or copies)
    - For each frame, creates LS task JSON:
      - "data": {"image": relative path to image}
      - "predictions": list of prediction dicts
      - Each prediction: {"result": [brush_result_dict]}
      - brush_result uses label_studio_converter.brush.mask2rle() for RLE encoding
      - type: "brushlabels", label: "fish"
    - For negative frames (empty masks list): still create task with empty predictions list
    - Writes tasks JSON array to output_dir/{project_name}_tasks.json
    - Returns path to tasks JSON file

    Function: `import_from_label_studio(annotations_path: Path) -> list[AnnotatedFrame]`
    - Reads LS export JSON (list of task dicts with completions/annotations)
    - For each task:
      - Extract image path from "data"
      - Extract brush annotations from "annotations"[0]["result"]
      - Decode RLE masks using label_studio_converter.brush.decode_rle()
      - Build binary masks (np.ndarray uint8)
    - Returns list of AnnotatedFrame dataclass: frame_id (str), image_path (Path), masks (list[np.ndarray]), camera_id (str)

    Function: `to_coco_dataset(annotated_frames: list[AnnotatedFrame], output_path: Path) -> Path`
    - Converts AnnotatedFrame list to COCO JSON format with RLE masks
    - Uses pycocotools.mask.encode(np.asfortranarray(mask)) for RLE encoding
    - Single category: {"id": 1, "name": "fish"}
    - Writes COCO JSON to output_path
    - Returns output_path

    **Dataclasses** (put in pseudo_labeler.py or a shared types module):
    - FrameAnnotation: frame_id, image_path, masks, camera_id
    - AnnotatedFrame: frame_id, image_path, masks, camera_id

    Update __init__.py to export SAMPseudoLabeler, export_to_label_studio, import_from_label_studio, to_coco_dataset, FrameAnnotation, AnnotatedFrame.

    **Tests:**
    - test_pseudo_labeler.py: Test with mock SAM2 predictor (don't require GPU). Test bbox conversion. Test mask-to-logit conversion. Test empty detections returns empty list.
    - test_label_studio.py: Test export creates valid JSON structure. Test round-trip (export -> mock LS edit -> import). Test negative frame handling. Test COCO conversion with pycocotools mock.
  </action>
  <verify>
    - `hatch run test tests/unit/segmentation/test_pseudo_labeler.py tests/unit/segmentation/test_label_studio.py` — all pass
    - `hatch run lint` — clean
    - `hatch run typecheck` — clean on new files
  </verify>
  <done>
    SAMPseudoLabeler generates masks from detections. Label Studio export creates valid task JSON with brush RLE masks. Import reads LS annotations back. COCO conversion produces valid COCO JSON with RLE. All tests pass.
  </done>
</task>

<task type="checkpoint:human-verify" gate="informational">
  <name>Task 2: Verify Label Studio import works</name>
  <files>N/A — verification only</files>
  <action>
    This is a human verification checkpoint. Claude has automated the SAM2 pseudo-labeling and Label Studio export/import pipeline. The user verifies the end-to-end annotation workflow works in practice.

    What was built:
    - SAM2 pseudo-labeling from MOG2 detections
    - Label Studio export (tasks JSON with brush RLE masks)
    - Label Studio import (reads corrected annotations)
    - COCO JSON conversion (for training)
  </action>
  <verify>
    1. Generate pseudo-labels on a small sample of frames (instructions in SUMMARY)
    2. Import the generated tasks JSON into a Label Studio project
    3. Verify masks appear as editable brush annotations on the images
    4. Correct a few masks and export from Label Studio
    5. Run import_from_label_studio on the export to confirm round-trip works
  </verify>
  <done>User confirms Label Studio round-trip works: pseudo-labels import, display correctly, can be edited, and export back successfully.</done>
</task>

</tasks>

<verification>
- All unit tests pass: `hatch run test tests/unit/segmentation/`
- SAMPseudoLabeler can be instantiated and called (integration test if GPU available)
- Label Studio JSON export is valid and importable
- COCO JSON output is valid pycocotools format
</verification>

<success_criteria>
SAM2 pseudo-labels are generated from MOG2 detections. Labels export to Label Studio brush format for human correction. Corrected annotations import back and convert to COCO JSON. The full annotation workflow is functional end-to-end.
</success_criteria>

<output>
After completion, create `.planning/phases/02-segmentation-pipeline/02-02-SUMMARY.md`
</output>
