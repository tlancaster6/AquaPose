---
phase: 15-stage-migrations
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/aquapose/core/detection/__init__.py
  - src/aquapose/core/detection/types.py
  - src/aquapose/core/detection/backends/__init__.py
  - src/aquapose/core/detection/backends/yolo.py
  - src/aquapose/core/detection/stage.py
  - src/aquapose/engine/config.py
  - tests/unit/core/detection/test_detection_stage.py
autonomous: true
requirements: [STG-01]

must_haves:
  truths:
    - DetectionStage satisfies engine.stages.Stage protocol via structural typing (isinstance check passes)
    - DetectionStage.run(context) reads frames from video, runs YOLO detection, populates context.detections and context.frame_count and context.camera_ids
    - DetectionStage loads YOLO model eagerly at construction time; FileNotFoundError raised if weights missing
    - Detection backend is selected via config.detection.detector_kind — YOLO only for now
    - No imports from engine/ in any core/detection/ module
  artifacts:
    - src/aquapose/core/detection/__init__.py
    - src/aquapose/core/detection/types.py
    - src/aquapose/core/detection/stage.py
    - src/aquapose/core/detection/backends/yolo.py
    - tests/unit/core/detection/test_detection_stage.py
  key_links:
    - DetectionStage.run() populates PipelineContext.detections, .frame_count, .camera_ids
    - Uses existing aquapose.segmentation.detector.YOLODetector and Detection dataclass
    - Config read from PipelineConfig.detection (DetectionConfig frozen dataclass)
---

<objective>
Port the Detection stage (Stage 1) as a pure Stage Protocol implementor in core/detection/.

Purpose: Detection is the first stage in the pipeline — it reads video frames, runs YOLO object detection, and produces per-frame per-camera detection lists. This plan creates the stage wrapper, backend registry, and interface tests.

Output: A DetectionStage class in core/detection/ that satisfies the Stage Protocol, loads a YOLO model at construction, and populates PipelineContext.detections when run.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/15-stage-migrations/15-CONTEXT.md

@src/aquapose/engine/stages.py
@src/aquapose/engine/config.py
@src/aquapose/pipeline/stages.py (v1.0 run_detection function — port this behavior)
@src/aquapose/pipeline/orchestrator.py (v1.0 orchestrator — shows how detection is wired)
@src/aquapose/segmentation/detector.py (existing YOLODetector and Detection dataclass)
@src/aquapose/io/video.py (VideoSet — used for frame reading)

<interfaces>
<!-- Engine contracts the executor needs -->

From src/aquapose/engine/stages.py:
```python
@runtime_checkable
class Stage(Protocol):
    def run(self, context: PipelineContext) -> PipelineContext: ...

@dataclass
class PipelineContext:
    frame_count: int | None = None
    camera_ids: list[str] | None = None
    detections: list[dict[str, list]] | None = None
    # ... other fields
```

From src/aquapose/engine/config.py:
```python
@dataclass(frozen=True)
class DetectionConfig:
    detector_kind: str = "yolo"
    stop_frame: int | None = None
    extra: dict[str, Any] = field(default_factory=dict)

@dataclass(frozen=True)
class PipelineConfig:
    video_dir: str = ""
    calibration_path: str = ""
    detection: DetectionConfig = ...
    # ... other stage configs
```

From src/aquapose/segmentation/detector.py:
```python
@dataclass
class Detection:
    bbox: tuple[int, int, int, int]
    mask: np.ndarray | None
    area: int
    confidence: float

class YOLODetector:
    def __init__(self, model_path, conf_threshold=0.5, iou_threshold=0.45, padding_fraction=0.15): ...
    def detect(self, frame: np.ndarray) -> list[Detection]: ...
```

From src/aquapose/io/video.py:
```python
class VideoSet:
    def __init__(self, camera_map: dict[str, Path], undistortion=None): ...
    @property
    def camera_ids(self) -> list[str]: ...
    def __enter__(self) -> VideoSet: ...
    def __iter__(self) -> Iterator[tuple[int, dict[str, np.ndarray]]]: ...
```

From src/aquapose/pipeline/orchestrator.py (v1.0 detection setup):
```python
_SKIP_CAMERA_ID = "e3v8250"
# video discovery: glob *.avi/*.mp4, infer camera_id from stem.split("-")[0]
# calibration loading, undistortion map computation, model construction
# one detector per camera
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create core/detection/ module with stage, types, and YOLO backend</name>
  <files>
    src/aquapose/core/detection/__init__.py
    src/aquapose/core/detection/types.py
    src/aquapose/core/detection/backends/__init__.py
    src/aquapose/core/detection/backends/yolo.py
    src/aquapose/core/detection/stage.py
    src/aquapose/engine/config.py
  </files>
  <action>
Create the core/detection/ package with consistent internal layout per the CONTEXT.md decisions:

1. **types.py** — Stage-specific types. Re-export `Detection` from `aquapose.segmentation.detector` (the existing dataclass). No new type needed yet — Detection is the canonical detection output type.

2. **backends/__init__.py** — Backend registry. Implement a simple `get_backend(kind: str, **kwargs)` factory that returns a detector instance. For now only "yolo" is supported (returns YOLODetector). Raise ValueError for unknown kinds. MOG2 is deferred per CONTEXT.md.

3. **backends/yolo.py** — Thin wrapper around existing `aquapose.segmentation.detector.YOLODetector`. The wrapper should:
   - Accept `model_path: str | Path` and optional detector kwargs (conf_threshold, iou_threshold, padding_fraction)
   - Load the model eagerly at construction (fail-fast if weights missing)
   - Expose a `detect(frame: np.ndarray) -> list[Detection]` method
   - This can simply instantiate and delegate to YOLODetector, or re-export it directly

4. **stage.py** — `DetectionStage` class that satisfies the Stage Protocol via structural typing. Constructor:
   - Takes `config: PipelineConfig` (import from engine.config is allowed — engine/ is imported by whoever wires stages, but the stage itself lives in core/ and must NOT import from engine/. Instead, accept the needed parameters directly)
   - CORRECTION: Per import boundary (ENG-07), core/ must NOT import from engine/. DetectionStage constructor should accept the parameters it needs directly: `video_dir: str | Path`, `calibration_path: str | Path`, `detector_kind: str = "yolo"`, `stop_frame: int | None = None`, `skip_camera_id: str = "e3v8250"`, `device: str = "cuda"`, and `**detector_kwargs`
   - Loads calibration data and undistortion maps at construction
   - Discovers camera videos (glob *.avi/*.mp4, infer camera_id from stem.split("-")[0], skip the excluded camera)
   - Creates the detector backend via the registry
   - `run(self, context: PipelineContext) -> PipelineContext`:
     - Opens VideoSet with undistortion
     - Iterates frames (up to stop_frame)
     - For each frame, runs detector.detect() on each camera
     - Populates context.detections (list of per-frame dicts), context.frame_count, context.camera_ids
     - Returns context

   Port the exact behavior from `pipeline.stages.run_detection` and `pipeline.orchestrator.reconstruct` (video discovery, calibration loading, undistortion setup). Extract hardcoded thresholds to constructor parameters. Log if any anomalies detected in the bug ledger.

5. **__init__.py** — Public API. Export `DetectionStage` and `Detection`.

6. **engine/config.py** — Add `model_path: str | None = None` and `device: str = "cuda"` fields to `DetectionConfig`. The model_path is needed for YOLO weight loading; device for GPU placement. Update load_config() to handle these fields (they flow through existing detection section).

CRITICAL RULES:
- core/detection/ must NOT import from engine/. PipelineContext is used as a type annotation only — use `from __future__ import annotations` and TYPE_CHECKING guard.
- The stage receives PipelineContext as an argument to run() but does not import the Protocol or engine module.
- Preserve v1.0 behavior exactly: same camera discovery logic, same skip camera, same detection output structure.
- Models load eagerly at construction. Wrong path = clear FileNotFoundError.
  </action>
  <verify>
    <automated>hatch run python -c "from aquapose.core.detection import DetectionStage, Detection; print('imports OK')"</automated>
  </verify>
  <done>
    - DetectionStage class exists in core/detection/stage.py
    - Constructor accepts video_dir, calibration_path, detector_kind, stop_frame, and detector kwargs
    - run() method signature matches Stage Protocol (takes PipelineContext, returns PipelineContext)
    - Backend registry resolves "yolo" to YOLODetector, raises ValueError for unknown kinds
    - No imports from engine/ in any core/detection/ source file
  </done>
</task>

<task type="auto">
  <name>Task 2: Interface tests for DetectionStage</name>
  <files>
    tests/unit/core/__init__.py
    tests/unit/core/detection/__init__.py
    tests/unit/core/detection/test_detection_stage.py
  </files>
  <action>
Create interface tests that validate DetectionStage conforms to the Stage Protocol and behaves correctly:

1. **test_detection_stage_satisfies_protocol** — Instantiate a DetectionStage (with mocked/synthetic inputs) and assert `isinstance(stage, Stage)` passes. This proves structural typing conformance.

2. **test_detection_stage_populates_context** — Create a DetectionStage with synthetic video frames (use a temporary directory with small test video files or mock VideoSet). Run `stage.run(PipelineContext())` and assert:
   - context.detections is not None and is a list
   - context.frame_count is set and > 0
   - context.camera_ids is set and is a list of strings
   - Each frame in detections is a dict mapping str to list

3. **test_backend_registry_unknown_kind_raises** — Call the backend factory with kind="unknown" and assert ValueError.

4. **test_import_boundary** — Inspect source of all modules in core/detection/ and assert no imports from aquapose.engine.

5. **test_missing_weights_raises** — Construct DetectionStage with a nonexistent model_path and assert FileNotFoundError or similar clear error at construction time (not at run time).

For tests needing video input, use unittest.mock to patch VideoSet iteration or create minimal synthetic test fixtures. The goal is to validate the Stage interface contract, not the detection algorithm itself.

Create __init__.py files for tests/unit/core/ and tests/unit/core/detection/ directories.
  </action>
  <verify>
    <automated>hatch run test tests/unit/core/detection/test_detection_stage.py -x -v</automated>
  </verify>
  <done>
    - All tests pass
    - DetectionStage is confirmed to satisfy Stage Protocol
    - Import boundary is verified — no engine/ imports in core/detection/
    - Backend registry error handling is tested
  </done>
</task>

</tasks>

<verification>
1. `isinstance(DetectionStage(...), Stage)` returns True
2. `hatch run test tests/unit/core/detection/ -v` — all pass
3. `hatch run check` — no lint or type errors in new files
4. Import boundary: grep for "engine" in src/aquapose/core/detection/ returns nothing
</verification>

<success_criteria>
- DetectionStage exists in core/detection/ and satisfies Stage Protocol
- YOLO backend loads eagerly, fails fast on missing weights
- run() populates context.detections, context.frame_count, context.camera_ids
- Interface tests pass
- No imports from engine/ in core/detection/
</success_criteria>

<output>
After completion, create `.planning/phases/15-stage-migrations/15-01-SUMMARY.md`
</output>
