---
phase: 08-end-to-end-integration-testing-and-benchmarking
plan: 03
type: execute
wave: 3
depends_on: ["08-01", "08-02"]
files_modified:
  - tests/e2e/test_reconstruct.py
autonomous: false
requirements:
  - OUT-01
  - OUT-02
  - OUT-03

must_haves:
  truths:
    - "reconstruct() runs end-to-end on real 13-camera video data with stop_frame=10, producing an HDF5 file and diagnostic report without crashing"
    - "The output HDF5 file contains valid Midline3D data readable by read_midline3d_results()"
    - "Diagnostic mode produces overlay videos, 3D animation, and a Markdown report in the output directory"
    - "User has visually inspected the diagnostic output and confirmed reconstruction quality is reasonable"
  artifacts:
    - path: "tests/e2e/test_reconstruct.py"
      provides: "End-to-end integration test calling reconstruct() on real data"
  key_links:
    - from: "tests/e2e/test_reconstruct.py"
      to: "src/aquapose/pipeline/orchestrator.py"
      via: "calls reconstruct() with real video data"
      pattern: "from aquapose\\.pipeline import reconstruct"
---

<objective>
Run the full reconstruction pipeline end-to-end on real 13-camera video data and visually verify the results.

Purpose: Validate that all stages chain correctly on real data, the HDF5 output is well-formed, and the visual outputs (overlays, 3D animation, report) allow quality assessment. This is the integration and acceptance test for the entire AquaPose v1 pipeline.

Output: `tests/e2e/test_reconstruct.py`, visual inspection of diagnostic output.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-end-to-end-integration-testing-and-benchmarking/08-CONTEXT.md
@.planning/phases/08-end-to-end-integration-testing-and-benchmarking/08-01-SUMMARY.md
@.planning/phases/08-end-to-end-integration-testing-and-benchmarking/08-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: End-to-end integration test script</name>
  <files>
    tests/e2e/test_reconstruct.py
  </files>
  <action>
Create `tests/e2e/test_reconstruct.py` with a `@pytest.mark.slow` test that:

1. Locates raw video data at `C:/Users/tucke/Desktop/Aqua/AquaPose/raw_videos` (skip test if not found)
2. Locates calibration JSON (find via glob in the data directory or use a known path)
3. Locates U-Net weights at `C:/Users/tucke/Desktop/Aqua/AquaPose/unet/best_model.pth` (skip if not found)
4. Creates a temporary output directory via `tmp_path` fixture
5. Calls `reconstruct(video_dir=..., calibration_path=..., output_dir=tmp_path, stop_frame=10, mode="diagnostic", unet_weights=...)`
6. Asserts:
   - `result.output_dir` exists and contains `midlines_3d.h5`
   - `result.stage_timing` has entries for all 5 stages
   - `result.midlines_3d` is a non-empty list
   - HDF5 file is readable via `read_midline3d_results()`
   - `report.md` exists in output_dir
   - At least one overlay video exists in `output_dir/overlays/`
7. Prints the stage timing summary table for manual review

Also include a smaller non-slow test `test_reconstruct_import` that just verifies the reconstruct function is importable and has the expected signature (inspect parameters).

The test should handle potential errors gracefully:
- If any stage fails, print the stage name and error for debugging
- Use `stop_frame=10` for fast iteration (processes only 10 frames)
- Mark with `@pytest.mark.slow` since it requires GPU and real data
  </action>
  <verify>
    - `hatch run check` passes on the test file
    - `hatch run test tests/e2e/test_reconstruct.py -k test_reconstruct_import` passes (import-only test)
    - `hatch run test-all tests/e2e/test_reconstruct.py -k test_reconstruct_e2e` runs on real data (requires GPU + data)
  </verify>
  <done>
    - E2E test exists and is runnable with `hatch run test-all`
    - Non-slow import test passes in CI
    - Test validates HDF5 output, diagnostic report, and overlay existence
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Visual inspection of diagnostic output</name>
  <what-built>
    Full reconstruction pipeline running on real 13-camera video data (10 frames) producing:
    - HDF5 file with 3D midline results
    - Per-camera overlay videos showing reprojected midlines on original frames
    - 3D animation of midlines in tank coordinates
    - Diagnostic Markdown report with timing and reconstruction statistics
  </what-built>
  <how-to-verify>
    1. Run: `hatch run test-all tests/e2e/test_reconstruct.py -k test_reconstruct_e2e -s`
    2. Check the output directory (printed by the test) for:
       a. Open `report.md` — verify timing table shows all 5 stages, reconstruction stats look reasonable
       b. Open one overlay video in `overlays/` — verify green midline polylines are drawn on fish bodies, not floating in space
       c. Open `midlines_3d.mp4` (or .gif) — verify fish midlines appear in a reasonable 3D volume, not collapsed to a plane
    3. If reconstruction quality is poor but pipeline runs without errors, that is acceptable for v1 — note quality issues for future improvement
    4. If pipeline crashes, describe the error
  </how-to-verify>
  <resume-signal>Type "approved" if pipeline runs and outputs look reasonable, or describe any issues found</resume-signal>
</task>

</tasks>

<verification>
- E2E test runs without crashing on 10 frames of real data
- HDF5 output is well-formed and readable
- Diagnostic report, overlay videos, and 3D animation are produced
- User confirms visual quality is acceptable for v1
</verification>

<success_criteria>
- The complete AquaPose pipeline runs end-to-end on real 13-camera video data
- All three output requirements (OUT-01, OUT-02, OUT-03) are satisfied with real data
- User has visually confirmed reconstruction quality
</success_criteria>

<output>
After completion, create `.planning/phases/08-end-to-end-integration-testing-and-benchmarking/08-03-SUMMARY.md`
</output>
