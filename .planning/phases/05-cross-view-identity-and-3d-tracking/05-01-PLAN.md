---
phase: 05-cross-view-identity-and-3d-tracking
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/aquapose/tracking/__init__.py
  - src/aquapose/tracking/associate.py
  - tests/unit/tracking/__init__.py
  - tests/unit/tracking/test_associate.py
autonomous: true
requirements:
  - TRACK-01
  - TRACK-02

must_haves:
  truths:
    - "RANSAC centroid clustering groups detections from multiple cameras into per-fish associations"
    - "Each association includes a triangulated 3D centroid with reprojection residual"
    - "Prior-guided seeding biases RANSAC toward previous-frame centroids for temporal consistency"
    - "Single-view detections are passed through as low-confidence flagged entries"
  artifacts:
    - path: "src/aquapose/tracking/associate.py"
      provides: "RANSAC centroid ray clustering algorithm"
      exports: ["ransac_centroid_cluster", "AssociationResult", "FrameAssociations"]
    - path: "src/aquapose/tracking/__init__.py"
      provides: "Package init with public API"
    - path: "tests/unit/tracking/test_associate.py"
      provides: "Unit tests for RANSAC clustering"
  key_links:
    - from: "src/aquapose/tracking/associate.py"
      to: "aquapose.calibration.projection"
      via: "triangulate_rays, RefractiveProjectionModel.cast_ray, RefractiveProjectionModel.project"
      pattern: "from aquapose\\.calibration\\.projection import"
---

<objective>
Implement RANSAC centroid ray clustering for cross-view fish identity association.

Purpose: This is the spatial association engine — given per-camera detections in a single frame, it determines which detections across cameras correspond to the same physical fish by casting refractive rays from 2D mask centroids, triangulating minimal camera subsets, and scoring consensus. This is the core algorithmic building block that all downstream tracking depends on.

Output: `src/aquapose/tracking/associate.py` with `ransac_centroid_cluster()` function, `AssociationResult` / `FrameAssociations` dataclasses, and unit tests.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-cross-view-identity-and-3d-tracking/05-CONTEXT.md
@.planning/phases/05-cross-view-identity-and-3d-tracking/05-RESEARCH.md

@src/aquapose/calibration/projection.py
@src/aquapose/segmentation/detector.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement RANSAC centroid ray clustering and data structures</name>
  <files>
    src/aquapose/tracking/__init__.py
    src/aquapose/tracking/associate.py
  </files>
  <action>
Create `src/aquapose/tracking/` package.

**`associate.py`** — RANSAC centroid ray clustering algorithm:

1. Define data structures:
   - `AssociationResult` dataclass: `fish_id: int`, `centroid_3d: np.ndarray` (shape (3,)), `reprojection_residual: float`, `camera_detections: dict[str, int]` (camera_id → detection_index), `n_cameras: int`, `confidence: float` (1.0 for high-confidence multi-view, lower for single-view flagged entries), `is_low_confidence: bool`
   - `FrameAssociations` dataclass: `associations: list[AssociationResult]`, `frame_index: int`, `unassigned: list[tuple[str, int]]` (camera_id, detection_index pairs that were not assigned to any fish)

2. Implement `ransac_centroid_cluster()`:
   ```python
   def ransac_centroid_cluster(
       detections_per_camera: dict[str, list[Detection]],
       models: dict[str, RefractiveProjectionModel],
       expected_count: int = 9,
       n_iter: int = 200,
       reprojection_threshold: float = 15.0,
       min_cameras: int = 2,
       seed_points: list[np.ndarray] | None = None,
   ) -> FrameAssociations:
   ```

   Algorithm:
   - Compute mask centroids for all detections: `np.where(det.mask > 0)` → mean row/col → `(u, v)` pixel
   - Cast refractive rays from each centroid using `model.cast_ray(pixel_tensor)`
   - **Prior-guided pass** (if seed_points provided): For each seed point, project into all cameras via `model.project()`, find nearest detection within `reprojection_threshold`, collect inlier set. Accept if ≥ `min_cameras` inliers.
   - **Random RANSAC iterations**: For remaining unassigned detections, repeat `n_iter` times:
     1. Sample 2 cameras randomly (each with at least 1 unassigned detection)
     2. Sample 1 unassigned detection per camera
     3. Triangulate via `triangulate_rays(origins, directions)` → candidate 3D centroid
     4. Score consensus: project candidate back to all cameras via `model.project()`, count detections within `reprojection_threshold` pixels of the projection
     5. Keep candidate with maximum inlier count (tie-break by minimum mean residual)
   - **Greedy assignment**: After finding best candidates (up to `expected_count`), greedily assign detections — each detection belongs to at most one fish. Sort candidates by inlier count descending, assign in order.
   - **Low-confidence entries**: Any detection still unassigned after all fish found → create single-view `AssociationResult` with `is_low_confidence=True`, `confidence` based on detection confidence, no triangulated centroid (use ray-depth heuristic: cast ray, place centroid at default tank depth ~0.5m along ray).
   - Compute per-association reprojection residual: mean pixel distance from projected 3D centroid to the assigned detection centroid in each inlier camera.

   Use XY-only for internal distance comparisons where noted in research (Z has 132x uncertainty). Use `torch.no_grad()` context for all projection/ray calls since this is inference-only.

3. Helper function `_compute_mask_centroid(mask: np.ndarray) -> tuple[float, float]`:
   Returns (u, v) — the mean of foreground pixel coordinates. Use `np.where(mask > 0)` → rows, cols → `(mean(cols), mean(rows))`. NOT the bbox center.

**`__init__.py`** — Package init with public API:
   ```python
   """Cross-view fish identity association and temporal tracking."""
   from .associate import AssociationResult, FrameAssociations, ransac_centroid_cluster
   __all__ = ["AssociationResult", "FrameAssociations", "ransac_centroid_cluster"]
   ```
   (Will be extended in Plans 02 and 03.)
  </action>
  <verify>
    `hatch run check` passes (lint + typecheck). Module imports: `python -c "from aquapose.tracking import ransac_centroid_cluster, AssociationResult, FrameAssociations"` succeeds.
  </verify>
  <done>
    `ransac_centroid_cluster()` implemented with prior-guided seeding, random RANSAC, greedy assignment, and low-confidence fallback. Data structures defined. Package importable.
  </done>
</task>

<task type="auto">
  <name>Task 2: Unit tests for RANSAC centroid clustering</name>
  <files>
    tests/unit/tracking/__init__.py
    tests/unit/tracking/test_associate.py
  </files>
  <action>
Create `tests/unit/tracking/` package and `test_associate.py`.

Use synthetic test fixtures (no GPU, no real data). Build mock `RefractiveProjectionModel` instances using the same pattern as Phase 3 tests (synthetic cameras at Z=0, water at Z=1.0, identity R, translation = -camera_position). Use `build_synthetic_rig` if available, or create minimal mock models.

**Test cases:**

1. **`test_two_fish_three_cameras`**: Create 3 mock cameras. Place 2 synthetic fish at known 3D positions. Project each fish into each camera to generate Detection objects with synthetic masks (small binary blobs at the projected pixel location). Run `ransac_centroid_cluster()`. Assert: 2 associations returned, each with ≥2 cameras, 3D centroids within 0.05m of ground truth XY, reprojection residual < `reprojection_threshold`.

2. **`test_prior_guided_improves_convergence`**: Same setup as test 1 but pass `seed_points` matching the ground truth positions. Assert: associations found with fewer iterations needed (or equivalently, same quality with `n_iter=20` instead of 200).

3. **`test_single_view_detection_flagged`**: Create 3 cameras, 1 fish visible in only 1 camera (other cameras have no detection for it). Run clustering. Assert: 1 association with `is_low_confidence=True`, `n_cameras=1`.

4. **`test_no_double_assignment`**: Create a scenario where 2 fish are close together. Assert each detection is assigned to at most one fish — no detection appears in two different `AssociationResult.camera_detections`.

5. **`test_mask_centroid_not_bbox_center`**: Create a detection with an off-center mask in its bbox. Verify `_compute_mask_centroid` returns the mask center-of-mass, not the bbox center.

6. **`test_empty_input`**: Pass empty `detections_per_camera`. Assert: `FrameAssociations` with empty associations list, no crash.

Use `pytest` fixtures for camera models and detection generation. Mark no tests as `@slow` — all synthetic, no real data needed.
  </action>
  <verify>
    `hatch run test tests/unit/tracking/test_associate.py` — all tests pass.
  </verify>
  <done>
    6 unit tests covering: basic multi-fish clustering, prior-guided seeding, single-view flagging, no double-assignment, mask centroid correctness, empty input handling. All pass.
  </done>
</task>

</tasks>

<verification>
- `hatch run check` passes (lint + typecheck)
- `hatch run test tests/unit/tracking/` — all tests pass
- `python -c "from aquapose.tracking import ransac_centroid_cluster"` — imports cleanly
- RANSAC correctly uses `triangulate_rays` and `cast_ray` from Phase 1 (not re-implemented)
- `_compute_mask_centroid` uses mask foreground pixels, not bbox center
</verification>

<success_criteria>
- RANSAC centroid clustering produces correct multi-camera associations on synthetic data
- Prior-guided mode improves convergence over random-only
- Low-confidence single-view detections are flagged, not silently dropped
- Reprojection residual computed and stored per association
- All unit tests pass
</success_criteria>

<output>
After completion, create `.planning/phases/05-cross-view-identity-and-3d-tracking/05-01-SUMMARY.md`
</output>
