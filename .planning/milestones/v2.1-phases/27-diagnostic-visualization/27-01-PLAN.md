---
phase: 27-diagnostic-visualization
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/aquapose/engine/tracklet_trail_observer.py
  - src/aquapose/engine/observer_factory.py
  - src/aquapose/engine/__init__.py
  - tests/unit/engine/test_tracklet_trail_observer.py
autonomous: true
requirements:
  - DIAG-01
must_haves:
  truths:
    - "User can produce per-camera centroid trail videos with fading tails and coasted/detected color distinction"
    - "User can produce a cross-camera association mosaic video color-coded by global fish ID"
    - "Diagnostic outputs are generated by an Observer (not a stage) and can be enabled via diagnostic mode without affecting pipeline computation"
    - "Global fish ID labels appear at trail heads; coasted frames use lighter/grayed color"
  artifacts:
    - path: "src/aquapose/engine/tracklet_trail_observer.py"
      provides: "TrackletTrailObserver class implementing Observer protocol"
      contains: "class TrackletTrailObserver"
    - path: "tests/unit/engine/test_tracklet_trail_observer.py"
      provides: "Unit tests for trail rendering, mosaic composition, color assignment"
      min_lines: 80
  key_links:
    - from: "src/aquapose/engine/tracklet_trail_observer.py"
      to: "PipelineComplete event"
      via: "on_event dispatches to _generate_trail_videos on PipelineComplete"
      pattern: "isinstance.*PipelineComplete"
    - from: "src/aquapose/engine/observer_factory.py"
      to: "TrackletTrailObserver"
      via: "_OBSERVER_MAP registration and diagnostic mode inclusion"
      pattern: "tracklet_trail.*TrackletTrailObserver"
    - from: "src/aquapose/engine/tracklet_trail_observer.py"
      to: "PipelineContext.tracks_2d and tracklet_groups"
      via: "getattr access on context object for tracklet data"
      pattern: "getattr.*tracks_2d|getattr.*tracklet_groups"
---

<objective>
Implement TrackletTrailObserver: per-camera centroid trail videos and cross-camera association mosaic, color-coded by global fish ID.

Purpose: Enable visual inspection of 2D tracking and cross-camera association quality. Centroid trails reveal tracking failures (ID switches, lost tracks), and the color-coded mosaic reveals association errors (same fish with different colors across cameras).

Output: TrackletTrailObserver class, observer factory wiring, unit tests.
</objective>

<execution_context>
@C:/Users/tucke/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/tucke/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
@.planning/phases/27-diagnostic-visualization/27-CONTEXT.md

@src/aquapose/engine/observers.py (Observer protocol, EventBus)
@src/aquapose/engine/events.py (PipelineComplete event)
@src/aquapose/engine/overlay_observer.py (reference pattern: mosaic, VideoSet, video writing)
@src/aquapose/engine/observer_factory.py (registration pattern)
@src/aquapose/engine/__init__.py (__all__ exports)
@src/aquapose/core/tracking/types.py (Tracklet2D: camera_id, track_id, frames, centroids, frame_status)
@src/aquapose/core/association/types.py (TrackletGroup: fish_id, tracklets, confidence)
@src/aquapose/core/context.py (PipelineContext: tracks_2d, tracklet_groups, camera_ids)
@src/aquapose/io/video.py (VideoSet context manager)

<interfaces>
<!-- Key types the executor needs -->

From src/aquapose/core/tracking/types.py:
```python
@dataclass(frozen=True)
class Tracklet2D:
    camera_id: str
    track_id: int
    frames: tuple        # tuple[int, ...]
    centroids: tuple     # tuple[tuple[float, float], ...]
    bboxes: tuple        # tuple[tuple[float, float, float, float], ...]
    frame_status: tuple  # tuple[str, ...] — "detected" or "coasted"
```

From src/aquapose/core/association/types.py:
```python
@dataclass(frozen=True)
class TrackletGroup:
    fish_id: int
    tracklets: tuple     # tuple[Tracklet2D, ...]
    confidence: float | None = None
```

From src/aquapose/core/context.py:
```python
@dataclass
class PipelineContext:
    camera_ids: list | None = None       # list[str]
    tracks_2d: dict | None = None        # dict[str, list[Tracklet2D]]
    tracklet_groups: list | None = None  # list[TrackletGroup]
    # ... other fields
```

From src/aquapose/engine/events.py:
```python
@dataclass(frozen=True)
class PipelineComplete(Event):
    run_id: str = ""
    elapsed_seconds: float = 0.0
    context: object = field(default=None, compare=False)
```

Observer protocol: implement `on_event(self, event: Event) -> None`
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement TrackletTrailObserver with per-camera trails and association mosaic</name>
  <files>src/aquapose/engine/tracklet_trail_observer.py</files>
  <action>
Create `src/aquapose/engine/tracklet_trail_observer.py` implementing the Observer protocol.

**Color palette** (Paul Tol 22-color, BGR for OpenCV — hardcoded, NOT imported):
```python
FISH_COLORS_BGR = [
    (112, 48, 0),    # blue #003070
    (76, 211, 234),   # gold #EAD34C
    (153, 170, 68),   # teal #44AA99
    (238, 204, 102),  # cyan #66CCEE
    (51, 136, 34),    # green #228833
    (51, 153, 153),   # olive #999933
    (119, 102, 238),  # coral #EE6677
    (170, 153, 238),  # rose #EE99AA
    (119, 51, 170),   # purple #AA3377
    (136, 34, 51),    # indigo #332288
    (51, 119, 238),   # orange #EE7733
    (17, 51, 204),    # red #CC3311
    (85, 34, 136),    # wine #882255
    (119, 51, 238),   # magenta #EE3377
    (153, 68, 170),   # plum #AA4499
    (170, 119, 68),   # steel #4477AA
    (221, 170, 119),  # sky #77AADD
    (119, 204, 221),  # sand #DDCC77
    (51, 204, 187),   # lime #BBCC33
    (102, 136, 238),  # peach #EE8866
    (187, 187, 187),  # gray #BBBBBB
    (119, 119, 119),  # dark gray #777777
]
```

**Constructor** `__init__(self, output_dir, video_dir, calibration_path, *, trail_length=30, fps=30.0, tile_scale=0.35)`:
- `output_dir`: Where to write output videos (observers/diagnostics/ subdirectory created inside)
- `video_dir`: Source camera video directory
- `calibration_path`: Calibration JSON path (needed for undistortion via VideoSet)
- `trail_length`: Number of frames in the fading tail (default 30)
- `fps`: Output video frame rate
- `tile_scale`: Downsampling factor per camera tile in mosaic (default 0.35 — 12 cameras at full res would be too large)

**`on_event(self, event: Event) -> None`**: Only respond to `PipelineComplete`. Extract context, guard on `tracks_2d` and `tracklet_groups` being non-None. Wrap generation in try/except with logger.warning (same fault tolerance as Overlay2DObserver).

**Color assignment**: Build a `fish_id -> BGR color` dict from `tracklet_groups`. Use `FISH_COLORS_BGR[fish_id % len(FISH_COLORS_BGR)]`. Also build a reverse mapping: `(camera_id, track_id) -> fish_id` from all tracklets in all groups. Tracklets NOT in any group get gray (#777777).

**Coasted color**: For coasted frames, blend the fish's assigned color toward gray. Use `coasted_color = tuple(int(c * 0.5 + 128 * 0.5) for c in base_color)` — this produces a lighter/washed-out version.

**Per-camera trail video generation** (`_generate_per_camera_trails`):
- For each camera in `camera_ids`, open the source video via VideoSet (same pattern as Overlay2DObserver).
- For each frame: look up all tracklets active in this camera at this frame index. For each tracklet, draw a fading polyline trail from `max(0, current_idx - trail_length)` to `current_idx` using the tracklet's centroids. Fade opacity linearly (oldest = 0.3 alpha, newest = 1.0 alpha). Use `cv2.addWeighted` on a trail overlay for alpha blending.
- At the trail head (current centroid), draw the global fish ID label using `cv2.putText` (FONT_HERSHEY_SIMPLEX, scale 0.6, thickness 2).
- Distinguish detected vs coasted: use the base fish color for detected frames, coasted color for coasted frames. The trail segments use the status at each point.
- Write to `{output_dir}/observers/diagnostics/tracklet_trails_{camera_id}.mp4` using `cv2.VideoWriter` with `mp4v` fourcc.
- Handle cameras with 0 tracklets: skip writing (do not create empty video).

**Association mosaic generation** (`_generate_association_mosaic`):
- Build a grid mosaic of all cameras (reuse the `_build_mosaic` and `_mosaic_dims` static methods from Overlay2DObserver — copy them as private methods, do NOT import from overlay_observer to avoid tight coupling).
- Grid layout: `n_cols = math.ceil(math.sqrt(n_cameras))`, `n_rows = math.ceil(n_cameras / n_cols)`. For 12 cameras: 4x3 grid.
- Each tile is downsampled by `tile_scale` before compositing.
- Draw the same centroid trails on each camera tile (same logic as per-camera, but on the downsampled tile).
- Add camera ID text in the top-left corner of each tile (FONT_HERSHEY_SIMPLEX, scale 0.4, white with black outline for readability).
- Write to `{output_dir}/observers/diagnostics/association_mosaic.mp4`.
- Cameras with 0 tracklets: show the plain video frame in the tile (no trails, just background).

**Performance note**: Build a per-camera frame-index lookup structure upfront: `dict[str, dict[int, list[tuple[Tracklet2D, int, int]]]]` mapping `camera_id -> frame_idx -> [(tracklet, idx_in_tracklet, fish_id)]`. This avoids scanning all tracklets for every frame.

**Module docstring**: Start with a one-line docstring per project rules.

**Imports**: Use `from __future__ import annotations`. Standard library: logging, math, pathlib. Third-party: cv2, numpy. Local: engine.events (Event, PipelineComplete). Use deferred import for io.video (VideoSet) and calibration.loader inside the generation methods (same pattern as Overlay2DObserver).
  </action>
  <verify>
    <automated>cd C:/Users/tucke/PycharmProjects/AquaPose && python -c "from aquapose.engine.tracklet_trail_observer import TrackletTrailObserver; print('import OK')"</automated>
  </verify>
  <done>TrackletTrailObserver class exists with on_event, _generate_per_camera_trails, _generate_association_mosaic methods. Handles PipelineComplete events, renders fading centroid trails with detected/coasted color distinction, draws global fish ID labels, produces per-camera MP4s and association mosaic MP4.</done>
</task>

<task type="auto">
  <name>Task 2: Wire observer into factory, update engine exports, write unit tests</name>
  <files>
    src/aquapose/engine/observer_factory.py
    src/aquapose/engine/__init__.py
    tests/unit/engine/test_tracklet_trail_observer.py
  </files>
  <action>
**observer_factory.py updates:**
1. Add import: `from aquapose.engine.tracklet_trail_observer import TrackletTrailObserver`
2. Add to `_OBSERVER_MAP`: `"tracklet_trail": TrackletTrailObserver`
3. In `build_observers()`, add TrackletTrailObserver to the `diagnostic` mode block:
   ```python
   observers.append(
       TrackletTrailObserver(
           output_dir=config.output_dir,
           video_dir=config.video_dir,
           calibration_path=config.calibration_path,
       )
   )
   ```
4. In the `extra_observers` loop, add an `elif cls is TrackletTrailObserver:` branch with same constructor args.

**engine/__init__.py updates:**
1. Add import: `from aquapose.engine.tracklet_trail_observer import TrackletTrailObserver`
2. Add `"TrackletTrailObserver"` to `__all__` (alphabetical order).

**Unit tests** (`tests/unit/engine/test_tracklet_trail_observer.py`):

Create synthetic test fixtures (no real video files needed — mock VideoSet):

1. **test_ignores_non_pipeline_complete_events**: Create observer, send StageComplete event, verify no video writing occurs.

2. **test_skips_when_tracks_2d_is_none**: Send PipelineComplete with context where tracks_2d is None. Verify graceful no-op.

3. **test_color_assignment_from_tracklet_groups**: Create mock tracklet_groups with 3 fish IDs. Verify `_build_color_map()` returns correct fish_id -> BGR mapping and (camera_id, track_id) -> fish_id reverse mapping.

4. **test_coasted_color_lighter_than_base**: Verify coasted color computation produces lighter/washed values (each channel closer to 128 than the base color).

5. **test_trail_lookup_structure**: Create 2 cameras with 3 tracklets total. Verify `_build_frame_lookup()` returns correct per-camera per-frame index.

6. **test_mosaic_dims**: Verify grid dimensions for 12 cameras (4x3), 1 camera (1x1), 7 cameras (3x3).

7. **test_build_observers_diagnostic_mode_includes_tracklet_trail**: Use a mock PipelineConfig and call `build_observers(config, "diagnostic", ...)`. Assert that at least one observer is a TrackletTrailObserver instance.

8. **test_observer_in_observer_map**: Verify `"tracklet_trail"` is in `_OBSERVER_MAP` and maps to `TrackletTrailObserver`.

9. **test_engine_init_exports**: Verify `TrackletTrailObserver` is importable from `aquapose.engine` and in `aquapose.engine.__all__`.

Use `unittest.mock.patch` for VideoSet and cv2.VideoWriter to avoid real I/O. Use `pytest` style (functions, not classes). Create Tracklet2D and TrackletGroup fixtures using the real dataclasses from core/.
  </action>
  <verify>
    <automated>cd C:/Users/tucke/PycharmProjects/AquaPose && hatch run python -m pytest tests/unit/engine/test_tracklet_trail_observer.py -x -v 2>&1 | tail -30</automated>
  </verify>
  <done>TrackletTrailObserver registered in observer factory for diagnostic mode and --add-observer. Engine __init__.py exports the class. 9+ unit tests pass covering event filtering, color assignment, coasted color, frame lookup, mosaic dimensions, factory wiring, and exports.</done>
</task>

</tasks>

<verification>
1. `python -c "from aquapose.engine import TrackletTrailObserver"` succeeds
2. `hatch run python -m pytest tests/unit/engine/test_tracklet_trail_observer.py -x -v` — all tests pass
3. `hatch run check` — lint + typecheck passes
4. TrackletTrailObserver appears in `build_observers()` output for diagnostic mode
5. Observer produces no side effects when tracks_2d or tracklet_groups are None
</verification>

<success_criteria>
- TrackletTrailObserver implements Observer protocol (on_event method)
- Per-camera trail videos render fading centroid trails with detected/coasted color distinction
- Association mosaic tiles all cameras in a grid with consistent color-coding by global fish ID
- Observer is passive (no pipeline state mutation), fault-tolerant (try/except with logging)
- Activated in diagnostic mode; can also be added via --add-observer tracklet_trail
- All unit tests pass; lint and typecheck clean
</success_criteria>

<output>
After completion, create `.planning/phases/27-diagnostic-visualization/27-01-SUMMARY.md`
</output>
